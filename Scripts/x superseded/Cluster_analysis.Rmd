---
title: "Clustering"
author: "Beatrice Cornu Hewitt" 
date: "`r Sys.time()`"
---
Identify the clusters in the NP and OP niches separately 
Then use Fischer's exact tests to see if the clusters differ with different exposure groups - age, sex, smoking, exposure to livestock, endotoxin etc. 

# Packages
```{r}
library(tidyverse);library(magrittr);library(glue);library(here);library(ggtext);library(fs);library(phyloseq);library(microbiomer);library(vegan);library(microbiome);library(decontam);library(reshape2);library(colorspace);library(scales);library(ggpubr);library(ggvenn);library(ggnewscale);library(RColorBrewer);library(paletteer);library(broom);library(rcartocolor);library(dendextend);library(ggmosaic);library(patchwork); library(fpc); library(ggdendro); library(nnet)

theme_set(theme_bw())
theme_update(axis.text.x = element_text(angle = 45, hjust=1),
             strip.text = element_text(colour = 'white'),
             strip.background =element_rect(fill="#2F4858", color = "#2F4858"))
```
# Functions
```{r}
clust_ind_plot <- function(dist, n, clust_method="average") {
  
  clust_ind_fnx <- function(dist, k, method = clust_method) {
    stats_k <- c(k=k, fpc::cluster.stats(dist, cutree(hclust(dist, method=method), k))[c("ch", "avg.silwidth")])
    return(stats_k)
  }
  clust_ind <- lapply(n, clust_ind_fnx, dist=dist) %>% 
    bind_rows %>%
    setNames(c("k", "Calinski-Harabasz", "Silhouette"))
  
  p <- clust_ind %>%
    gather(index, value, -k) %>%
    ggplot(aes(x=k, y=value)) +
    geom_point() +
    geom_line() +
    facet_wrap(vars(index), scales="free_y")
  return(list(plot=p, data=clust_ind))
}


noLabel <- function(x) {
  if (stats::is.leaf(x)) {
    attr(x, "label") <- NULL }
  return(x)
}


prep_hm_data <- function(otu_ordered) {
  hm_data <- otu_ordered %>%
    data.frame(check.names = F) %>%
    rownames_to_column("OTU") %>% 
    pivot_longer(-OTU, names_to = "sample_id", values_to = "RA") %>%
    mutate(RA = if_else(RA == 0, NA_real_, RA),
           OTU = format_OTU(OTU) %>% fct_inorder() %>% fct_rev(),
           sample_id = fct_inorder(sample_id))
  return(hm_data)
}


prep_hm_data <- function(otu_ordered) {
  otu_ordered <- otu_ordered %>%
    mutate(across(-OTU, as.character))  # Convert all columns except OTU to character
  
  hm_data <- otu_ordered %>%
    data.frame(check.names = FALSE) %>%
    rownames_to_column("OTU") %>% 
    pivot_longer(cols = -OTU, names_to = "sample_id", values_to = "RA") %>%
    mutate(RA = if_else(RA == "0", NA_real_, as.numeric(RA)),  # Ensure RA is numeric with NA for zero values
           OTU = format_OTU(OTU) %>% fct_inorder() %>% fct_rev(),
           sample_id = fct_inorder(sample_id))
  
  return(hm_data)
}


create_dendro_gg <- function(hc, hang_height=0.05, size = 0.4) {
  suppressPackageStartupMessages(library(dendextend))
  library(ggdendro)
  
  dendro_data_bl <- hc %>% as.dendrogram %>% hang.dendrogram(hang_height=hang_height) %>% dendro_data
  dendro_data_bl$segments$yend[dendro_data_bl$segments$yend<0] <- 0
  
  dendro_data_gr <- hc %>% as.dendrogram %>% dendro_data
  hc_order <- dendro_data_gr$labels$label
  
  plot <- ggplot(segment(dendro_data_gr)) +
    geom_segment(aes(x=x, y=y, xend=xend, yend=yend),colour="white", size = size) + 
    geom_segment(data=segment(dendro_data_bl),aes(x=x, y=y, xend=xend, yend=yend),  size = size) +
    scale_x_continuous(expand = rep(1/length(hc_order)/2, 2)) + 
    scale_y_continuous(expand=c(0,0.02)) +
    #theme(plot.margin=unit(c(0,0,0,0),"lines")) +
    theme_void()
  return(list(plot=plot, hc_order=hc_order)) 
}
```

# Data
## CP (all) and GF (all)
```{r}
ps_new_metadata_RFpreds <- readRDS("../Output/Phyloseq/ps_complete_new_metadata_RFpreds.rds")
# Remove any samples from pneumonia patients as not used in the analysis
ps_cpall_gf <- subset_samples(ps_new_metadata_RFpreds, population != "GP")
ps_cpall_gf <- prune_taxa(taxa_sums(ps_cpall_gf) > 0, ps_cpall_gf) # Also remove taxa that are not in the ps_cpall_gf object
```

### NP 
```{r}
# First, we remove the low abundant ASVs, calculate the relative abundance of each ASV per sample and subset the nasopharyngeal samples
ps_RA_cpall_gf_np <- ps_cpall_gf %>% pres_abund_filter() %>% to_RA() %>%
  prune_samples(sample_data(ps_cpall_gf)$niche == "NP", .) 
# A total of 2567 ASVs were found to be present at or above a level of confident detection (0.1% relative abundance) in at least 2 samples (n = 17462 ASVs excluded).

# Next, using the OTU table and meta data, we created a Bray Curtis dissimilarity matrix. This matrix is used to determine the number of clusters/which samples have a more similar microbial profile (belong to the same cluster)
meta_cpall_gf_np <- meta_to_df(ps_RA_cpall_gf_np)
  
otu_cpall_gf_np <- as(otu_table(ps_RA_cpall_gf_np), "matrix")
if(taxa_are_rows(ps_RA_cpall_gf_np)){otu_cpall_gf_np <- t(otu_cpall_gf_np)} 
otu_cpall_gf_np <- as.data.frame(otu_cpall_gf_np)
# Compute BC distances
ord_cpall_gf_np <- vegdist(otu_cpall_gf_np, method = "bray") 

# We used complete linkage to create the phylogenetic tree (hierarchical clustering). The method is based on maximum distance; the similarity of any two clusters is the similarity of their most dissimilar pair.
hc_cpall_gf_np_clust <- hclust(ord_cpall_gf_np, method = "complete")
# Reorder 'otu_np' based on the clustering order
otu_hc_cpall_gf_np_order_clust <- otu_cpall_gf_np[hc_cpall_gf_np_clust$order,]

# The Calinski-Harabasz and Silhouette methods were used to determine the appropriate location to cut the tree. Higher value of indices means the clusters are dense and well separated. Here, we looked for a peak or at least an abrupt elbow on the line plot of the indices.
CalHara_silhouette_indices_cpall_gf_np <- clust_ind_plot(ord_cpall_gf_np, seq(2, 25, by = 1), clust_method="complete")
write.csv(CalHara_silhouette_indices_cpall_gf_np$data, "../Output/Cluster_analysis/CPall_GF_NP/calinski_harabasz_silhouette_indices_cpall_gf_np.csv")

# Calinski-Harabasz Index: A higher value indicates well-separated clusters with high intra-cluster similarity.
# Silhouette: The optimal number of clusters typically shows the highest silhouette score, suggesting well-separated and compact clusters.

# look for the points where there are peaks or elbows in the curve

# Create dendogram
dend_cpall_gf_np <- as.dendrogram(hc_cpall_gf_np_clust)
 
# 4 clusters
dend_4clusters <- color_branches(dend_cpall_gf_np, k = 4, groupLabels=T)
plot(stats::dendrapply(dend_4clusters, noLabel))

# 5 clusters
dend_5clusters <- color_branches(dend_cpall_gf_np, k = 5, groupLabels=T)
plot(stats::dendrapply(dend_5clusters, noLabel))
cluster_assignments_5 <- cutree(dend_cpall_gf_np, k = 5)
cluster_counts_5 <- table(cluster_assignments_5)
print(cluster_counts_5)

# 6 clusters
dend_6clusters <- color_branches(dend_cpall_gf_np, k = 6, groupLabels=T)
plot(stats::dendrapply(dend_6clusters, noLabel))
cluster_assignments_6 <- cutree(dend_cpall_gf_np, k = 6)
cluster_counts_6 <- table(cluster_assignments_6)
print(cluster_counts_6)

# 7 clusters
dend_7clusters <- color_branches(dend_cpall_gf_np, k = 7, groupLabels=T)
plot(stats::dendrapply(dend_7clusters, noLabel))
cluster_assignments_7 <- cutree(dend_cpall_gf_np, k = 7)
cluster_counts_7 <- table(cluster_assignments_7)
print(cluster_counts_7)

# 8 clusters
dend_8clusters <- color_branches(dend_cpall_gf_np, k = 8, groupLabels=T)
plot(stats::dendrapply(dend_8clusters, noLabel))
cluster_assignments_8 <- cutree(dend, k = 8)
cluster_counts_8 <- table(cluster_assignments_8)
print(cluster_counts_8)

# 9 clusters
dend_9clusters <- color_branches(dend_cpall_gf_np, k = 9, groupLabels=T)
plot(stats::dendrapply(dend_9clusters, noLabel))
cluster_assignments_9 <- cutree(dend, k = 9)
cluster_counts_9 <- table(cluster_assignments_9)
print(cluster_counts_9)

# 10 clusters
dend_10clusters <- color_branches(dend_cpall_gf_np, k = 10, groupLabels=T)
plot(stats::dendrapply(dend_10clusters, noLabel))
cluster_assignments_10 <- cutree(dend, k = 10)
cluster_counts_10 <- table(cluster_assignments_10)
print(cluster_counts_10)

# 11 clusters
dend_11clusters <- color_branches(dend_cpall_gf_np, k = 11, groupLabels=T)
plot(stats::dendrapply(dend_11clusters, noLabel))
cluster_assignments_11 <- cutree(dend, k = 11)
cluster_counts_11 <- table(cluster_assignments_11)
print(cluster_counts_11)

# 12 clusters
dend_12clusters <- color_branches(dend_cpall_gf_np, k = 12, groupLabels=T)
plot(stats::dendrapply(dend_12clusters, noLabel))
# check number per cluster
cluster_assignments_12 <- cutree(dend, k = 12)
cluster_counts_12 <- table(cluster_assignments_12)
print(cluster_counts_12)

# 13 clusters
dend_13clusters <- color_branches(dend_cpall_gf_np, k = 13, groupLabels=T)
plot(stats::dendrapply(dend_13clusters, noLabel))
cluster_assignments_13 <- cutree(dend, k = 13)
cluster_counts_13 <- table(cluster_assignments_13)
print(cluster_counts_13)

# 14 clusters
dend_14clusters <- color_branches(dend_cpall_gf_np, k = 14, groupLabels=T)
plot(stats::dendrapply(dend_14clusters, noLabel))
cluster_assignments_14 <- cutree(dend, k = 14)
cluster_counts_14 <- table(cluster_assignments_14)
print(cluster_counts_14)
# 15 clusters
dend_15clusters <- color_branches(dend_cpall_gf_np, k = 15, groupLabels=T)
plot(stats::dendrapply(dend_15clusters, noLabel))
cluster_assignments_15 <- cutree(dend, k = 15)
cluster_counts_15 <- table(cluster_assignments_15)
print(cluster_counts_15)


# 9 clusters appears optimal
# k = 9
dend_9clusters <- color_branches(dend_cpall_gf_np, k = 9, groupLabels=T)
plot(stats::dendrapply(dend_9clusters, noLabel))
cluster_assignments_9 <- cutree(dend, k = 9)
cluster_counts_9 <- table(cluster_assignments_9)
print(cluster_counts_9)

# The function 'cuttree' is used to cut the tree at k = 9 
groups_cpall_gf_np_c9 <- cutree(hc_cpall_gf_np_clust, k = 9)
ps_RA_cpall_gf_np@sam_data$cluster <- groups_cpall_gf_np_c9[order(rownames(ps_RA_cpall_gf_np@sam_data))]
ps_RA_cpall_gf_np@sam_data$cluster <- ps_RA_cpall_gf_np@sam_data$cluster %>% as.character()

# Determine the top 3 ASVs for each cluster
otu_cpall_gf_np <- as(otu_table(ps_RA_cpall_gf_np), "matrix")
if (taxa_are_rows(ps_RA_cpall_gf_np)) {
  otu_cpall_gf_np <- t(otu_cpall_gf_np)  # Ensure ASVs are columns, samples are rows
}

# Extract sample metadata with cluster information
sample_data_cpall_gf_np <- data.frame(ps_RA_cpall_gf_np@sam_data)
# Combine the OTU table with the sample cluster data
otu_cpall_gf_np_with_clusters <- cbind(cluster = sample_data_cpall_gf_np$cluster, otu_cpall_gf_np)
otu_cpall_gf_np_with_clusters <- as.data.frame(otu_cpall_gf_np_with_clusters)
otu_cpall_gf_np_with_clusters$cluster <- as.factor(otu_cpall_gf_np_with_clusters$cluster)
# Convert all ASV abundances to numeric
otu_cpall_gf_np_with_clusters[-1] <- lapply(otu_cpall_gf_np_with_clusters[-1], as.numeric)
# Sum ASV abundances for each cluster
asv_sum_by_cluster_cpall_gf_np <- otu_cpall_gf_np_with_clusters %>%
  group_by(cluster) %>%
  summarise(across(where(is.numeric), sum, na.rm = TRUE))
# Convert back to data frame for further processing
asv_sum_by_cluster_cpall_gf_np <- as.data.frame(asv_sum_by_cluster_cpall_gf_np)
# Find the top 3 most abundant ASVs in each cluster and their percentage
top_3_asvs_cpall_gf_np <- apply(asv_sum_by_cluster_cpall_gf_np[, -1], 1, function(x) {
  # Get total abundance in the cluster for calculating percentages
  total_abundance_cpall_gf_np <- sum(x, na.rm = TRUE)
  # Get names and values of the top 3 ASVs
  top_3_indices_cpall_gf_np <- order(x, decreasing = TRUE)[1:3]
  top_3_asv_names_cpall_gf_np <- names(x)[top_3_indices_cpall_gf_np]
  top_3_asv_values_cpall_gf_np <- x[top_3_indices_cpall_gf_np]
  # Calculate percentages
  top_3_asv_percentages_cpall_gf_np <- (top_3_asv_values_cpall_gf_np / total_abundance_cpall_gf_np) * 100
  # Combine ASV names and percentages into a string for each cluster
  result <- paste0(top_3_asv_names_cpall_gf_np, ": ", round(top_3_asv_percentages_cpall_gf_np, 2), "%", collapse = "; ")
  return(result)
})

# Combine results with cluster information
top_3_asvs_df_cpall_gf_np <- data.frame(cluster = asv_sum_by_cluster_cpall_gf_np$cluster, Top_3_ASVs = top_3_asvs_cpall_gf_np)
# Display the top 3 ASVs for each cluster along with their percentages
print(top_3_asvs_df_cpall_gf_np)

#### Rename clusters ####
# If an ASV is >40% of the total abundance in a cluster: Name the cluster after that ASV only, as it is the dominant contributor.
# If the top ASV is between 20-40% of the total abundance: Use the two most abundant ASVs to name the cluster.
# If the top ASV is <20% of the total abundance: Use the top three ASVs to name the cluster, as none of the ASVs dominate significantly.

get_cluster_name <- function(top_asvs_string) {
  asv_info <- strsplit(top_asvs_string, "; ")[[1]]
  asv_names <- sapply(asv_info, function(x) strsplit(x, ": ")[[1]][1])
  asv_percentages <- as.numeric(sapply(asv_info, function(x) sub("%", "", strsplit(x, ": ")[[1]][2])))
  
  if (asv_percentages[1] > 40) {
    return(paste0(asv_names[1], "-dominated cluster"))
  } else if (asv_percentages[1] > 20) {
    return(paste0(asv_names[1], " and ", asv_names[2], "-dominated cluster"))
  } else {
    return(paste0(asv_names[1], ", ", asv_names[2], ", and ", asv_names[3], "-dominated cluster"))
  }
}

# Rename based on these rules
top_3_asvs_df_cpall_gf_np$Cluster_Name <- sapply(top_3_asvs_df_cpall_gf_np$Top_3_ASVs, get_cluster_name)
top_3_asvs_df_cpall_gf_np$Cluster_Name

# [1] "Dolosigranulum_pigrum_1-dominated cluster"                                              
# [2] "Corynebacterium_3-dominated cluster"                                                    
# [3] "Moraxella_5-dominated cluster"                                                          
# [4] "Staphylococcus_2-dominated cluster"                                                     
# [5] "Moraxella_lincolnii_47-dominated cluster"                                               
# [6] "Streptococcus_23 and Streptococcus_8-dominated cluster"                                 
# [7] "Corynebacterium_7-dominated cluster"                                                    
# [8] "Corynebacterium_28-dominated cluster"                                                   
# [9] "Fusobacterium_nucleatum_72, Streptococcus_150, and Prevotellaceae_254-dominated cluster"

# Shorten the names made above for plotting 
# Define the new cluster names in the same order as the original clusters
new_cluster_names_cpall_gf_np <- c(
  "Dolo(1) clust",
  "Cor(3) clust",
  "Mor(5) clust",
  "Staph(2) clust",
  "Mor(47) clust",
  "Strep(23)/Strep(8) clust",
  "Cor(7) clust",
  "Cor(28) clust",
  "Fus(72)/Strep(150)/Prev(254) clust"
)

# Assign the new names to 'Cluster_Name' in 'top_3_asvs_df'
top_3_asvs_df_cpall_gf_np$Cluster_Name <- new_cluster_names_cpall_gf_np

# Update the clusters in the sample data to use the new names
ps_RA_cpall_gf_np@sam_data$cluster <- top_3_asvs_df_cpall_gf_np$Cluster_Name[match(ps_RA_cpall_gf_np@sam_data$cluster, top_3_asvs_df_cpall_gf_np$cluster)]
# Convert to character
ps_RA_cpall_gf_np@sam_data$cluster <- as.character(ps_RA_cpall_gf_np@sam_data$cluster)

# Count the number of samples in each cluster
cluster_counts_cpall_gf_np <- as.data.frame(table(ps_RA_cpall_gf_np@sam_data$cluster))
colnames(cluster_counts_cpall_gf_np) <- c("Cluster", "Count")

# Calculate the relative proportions of each cluster
cluster_counts_cpall_gf_np$Proportion <- cluster_counts_cpall_gf_np$Count / sum(cluster_counts_cpall_gf_np$Count)

write.csv(cluster_counts_cpall_gf_np, "../Output/Cluster_analysis/CPall_GF_NP/cluster_counts_cpall_gf_np.csv")

# Create the plot with geom_bar for vertical stacking
bar_clusters_cpall_gf_np <- ggplot(data = cluster_counts_cpall_gf_np, aes(x = Cluster, y = (Proportion*100), fill = Cluster)) +
  geom_bar(stat = "identity") +  # Use stat = "identity" to directly use Proportion
  labs(title = "Bar Plot of Clusters in Control Population and Goat farmers",
       x = "Clusters",            # X-axis now represents clusters
       y = "% of samples",          # Y-axis represents proportions
       fill = "Cluster") +
  scale_fill_manual(values = c(paletteer_d("pals::stepped")[c(13,20,10,16,1,18,21,5,12)])) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),      # Remove x-axis labels if needed
        axis.ticks.x = element_blank(),     # Remove x-axis ticks if needed
        legend.position = "right")

bar_clusters_cpall_gf_np
ggsave("../Output/Cluster_analysis/CPall_GF_NP/Bar_plot_cluster_proportions_clusters.svg", bar_clusters_cpall_gf_np, width = 8, height = 5)

```

#### Visualisations for manuscript
```{r}
dendro_cpall_gf_np <- create_dendro_gg(hc_cpall_gf_np_clust, size = 0.15)

otu_hm_cpall_gf_np <- as(otu_table(ps_RA_cpall_gf_np), "matrix")
otu_hm_cpall_gf_np_order <- otu_hm_cpall_gf_np[order(rowMeans(otu_hm_cpall_gf_np), decreasing = T)[1:40], hc_cpall_gf_np_clust$order]
meta_hm_cpall_gf_np_order <- ps_RA_cpall_gf_np %>% meta_to_df()
meta_hm_cpall_gf_np_order <- meta_hm_cpall_gf_np_order[hc_cpall_gf_np_clust$order,]
meta_hm_cpall_gf_np_order$cluster

all(colnames(otu_hm_cpall_gf_np_order) == hc_cpall_gf_np_clust$labels[hc_cpall_gf_np_clust$order])

prep_hm_data <- function(otu_ordered) {
  # Convert matrix to data frame and move row names to a column called "OTU"
  otu_ordered <- otu_ordered %>%
    as.data.frame() %>%
    tibble::rownames_to_column("OTU")
  # Format data for heatmap
  hm_data <- otu_ordered %>%
    tidyr::pivot_longer(cols = -OTU, names_to = "sample_id", values_to = "RA") %>%
    dplyr::mutate(
      RA = dplyr::if_else(RA == "0", NA_real_, as.numeric(RA)),  # Convert "0" to NA for heatmap
      OTU = format_OTU(OTU) %>% forcats::fct_inorder() %>% forcats::fct_rev(),  # Format OTUs
      sample_id = forcats::fct_inorder(sample_id)
    )
  return(hm_data)
}

# Call prep_hm_data with the data frame
hm_cpall_gf_np_data <- prep_hm_data(otu_hm_cpall_gf_np_order)

# Ensure OTU data is ordered by hierarchical clustering order
otu_hm_cpall_gf_np_order <- otu_hm_cpall_gf_np[order(rowMeans(otu_hm_cpall_gf_np), decreasing = TRUE), hc_cpall_gf_np_clust$order]
meta_hm_cpall_gf_np_order <- meta_hm_cpall_gf_np_order[hc_cpall_gf_np_clust$order, ]

# Overall heatmap
hm_cpall_gf_np <- hm_cpall_gf_np_data %>%
  ggplot(aes(x = sample_id, y = OTU, fill = RA)) +
  geom_tile() +
  scale_fill_gradientn(name="Relative abundance", 
                       colors = carto_pal(7, "BurgYl"), 
                       na.value = "white", 
                       guide = guide_colorbar(title.position = "top", title.hjust = 0.5)) +
  theme_grey(base_size = 10) + 
  theme(axis.text.x = element_blank(), 
        axis.text.y = element_markdown(size = 10),  # Set y-axis text size
        axis.ticks.x = element_blank(), 
        legend.position = "bottom",
        legend.key.height = grid::unit(0.2, "cm"),
        legend.key.width = grid::unit(0.8, "cm"),
        legend.text = element_text(size = 10),      # Set legend text size
        plot.background = element_blank()) +
  xlab("Sample") + 
  ylab("ASV")
hm_cpall_gf_np

# Cluster plot
# Ensure the metadata (meta_hm_cpall_gf_np_order) is also ordered according to the same clustering order
meta_hm_cpall_gf_np_order <- meta_hm_cpall_gf_np_order[hc_cpall_gf_np_clust$order, ]
# Reorder the Sample IDs for Consistency
meta_hm_cpall_gf_np_order$sample_id <- factor(meta_hm_cpall_gf_np_order$sample_id,
                                               levels = hc_cpall_gf_np_clust$labels[hc_cpall_gf_np_clust$order])

# Reorder data for the Cluster Plot
meta_hm_cpall_gf_np_order$cluster <- factor(meta_hm_cpall_gf_np_order$cluster,
                                             levels =unique(meta_hm_cpall_gf_np_order$cluster[order(meta_hm_cpall_gf_np_order$cluster)]))

hm_cluster_cpall_gf_np <- meta_hm_cpall_gf_np_order %>%
  ggplot(aes(x = sample_id, y = "Cluster", fill = cluster)) +
  theme_void() + 
  geom_tile() + 
  scale_fill_manual(values = c(paletteer_d("pals::stepped")[c(13,20,10,16,1,18,21,5,12)])) + 
  labs(fill = "Cluster") + 
  theme(axis.text.y = element_text(size = 10),  # Set y-axis text size
        axis.ticks.length.y = unit(.18, "cm"),
        legend.direction = "vertical", 
        legend.box = "vertical",
        legend.key.size = unit(0.8, "lines"),
        legend.text = element_text(size = 10))    # Set legend text size
hm_cluster_cpall_gf_np

# Population plot 
hm_pop_cpall_gf_np <- meta_hm_cpall_gf_np_order %>%
  ggplot(aes(x = sample_id, y = "Population", fill = population)) +
  theme_void() + 
  geom_tile() + 
  scale_fill_brewer(palette = "Set2") + 
  labs(fill = "Population") + 
  theme(axis.text.y = element_text(size = 10),  # Set y-axis text size
        axis.ticks.length.y = unit(.18, "cm"),
        legend.direction = "vertical", 
        legend.box = "vertical",
        legend.key.size = unit(0.8, "lines"),
        legend.text = element_text(size = 10))    # Set legend text size
hm_pop_cpall_gf_np

# Prevalence plot
# Using original phyloseq (not RA)
df_pres_np <- ps_cpall_gf %>% ps_to_df()
# Check dimensions
colnames(df_pres_np)
dim(df_pres_np)
# Convert counts to binary
df_pres_np[, colnames(df_pres_np)[700:1989]] <- lapply(df_pres_np[, colnames(df_pres_np)[700:1989]], function(x) ifelse(x > 2, 1, 0))
df_pres_np <- df_pres_np[700:1989]

prev <- colMeans(df_pres_np)
prev_np <- data.frame(Taxa = colnames(df_pres_np), Prevalence = prev)
prev_np$Taxa <- format_OTU(prev_np$Taxa)
prev_np <- subset(prev_np, Taxa %in% hm_cpall_gf_np_data$OTU)
prev_np$Taxa <- factor(prev_np$Taxa, levels = levels(hm_cpall_gf_np_data$OTU))

p_prev_np <- ggplot(prev_np, aes(x = Prevalence, y = Taxa)) +
  geom_bar(stat = "identity", fill = "azure4", width = 0.5) +
  labs(x = "Prevalence") +
  theme_minimal() + 
  theme(axis.text.y = element_blank(), 
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank()) +
  scale_x_continuous(breaks = c(0, 0.5, 1),
                     labels = scales::percent_format())
p_prev_np
# Make patchwork of plot
layout_cp_gf <- "
AAAAAA#
AAAAAA#
AAAAAA#
BBBBBB#
CCCCCC#
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
"

dendro_cpall_gf_np$plot + hm_pop_cpall_gf_np + hm_cluster_cpall_gf_np + hm_cpall_gf_np + p_prev_np + plot_layout(design = layout_cp_gf, guides = "collect") & theme(legend.position = 'bottom')

ggsave("../Output/Cluster_analysis/CPall_GF_NP/heatmap_cluster_cpall_gf_np.svg", height = 10, width = 8)
ggsave("../Output/Cluster_analysis/CPall_GF_NP/heatmap_cluster_cpall_gf_np.png", height = 10, width = 8)






```

### OP 
```{r}
# First, we remove the low abundant ASVs, calculate the relative abundance of each ASV per sample and subset the nasopharyngeal samples
ps_RA_cpall_gf_op <- ps_cpall_gf %>% pres_abund_filter() %>% to_RA() %>%
  prune_samples(sample_data(ps_cpall_gf)$niche == "OP", .) 
# A total of 2567 ASVs were found to be present at or above a level of confident detection (0.1% relative abundance) in at least 2 samples (n = 17462 ASVs excluded).

# Next, using the OTU table and meta data, we created a Bray Curtis dissimilarity matrix. This matrix is used to determine the number of clusters/which samples have a more similar microbial profile (belong to the same cluster)
meta_cpall_gf_op <- meta_to_df(ps_RA_cpall_gf_op)
  
otu_cpall_gf_op <- as(otu_table(ps_RA_cpall_gf_op), "matrix")
if(taxa_are_rows(ps_RA_cpall_gf_op)){otu_cpall_gf_op <- t(otu_cpall_gf_op)} 
otu_cpall_gf_op <- as.data.frame(otu_cpall_gf_op)
# Compute BC distances
ord_cpall_gf_op <- vegdist(otu_cpall_gf_op, method = "bray") 

# We used complete linkage to create the phylogenetic tree (hierarchical clustering). The method is based on maximum distance; the similarity of any two clusters is the similarity of their most dissimilar pair.
hc_cpall_gf_op_clust <- hclust(ord_cpall_gf_op, method = "complete")
# Reorder 'otu_op' based on the clustering order
otu_hc_cpall_gf_op_order_clust <- otu_cpall_gf_op[hc_cpall_gf_op_clust$order,]

# The Calinski-Harabasz and Silhouette methods were used to determine the appropriate location to cut the tree. Higher value of indices means the clusters are dense and well separated. Here, we looked for a peak or at least an abrupt elbow on the line plot of the indices.
CalHara_silhouette_indices_cpall_gf_op <- clust_ind_plot(ord_cpall_gf_op, seq(2, 25, by = 1), clust_method="complete")
write.csv(CalHara_silhouette_indices_cpall_gf_op$data, "../Output/Cluster_analysis/CPall_GF_OP/calinski_harabasz_silhouette_indices_cpall_gf_op.csv")

# Calinski-Harabasz Index: A higher value indicates well-separated clusters with high intra-cluster similarity.
# Silhouette: The optimal number of clusters typically shows the highest silhouette score, suggesting well-separated and compact clusters.

# look for the points where there are peaks or elbows in the curve

# Create dendogram
dend_cpall_gf_op <- as.dendrogram(hc_cpall_gf_op_clust)

# 2 clusters
dend_2clusters <- color_branches(dend_cpall_gf_op, k = 2, groupLabels=T)
plot(stats::dendrapply(dend_2clusters, noLabel))
cluster_assignments_2 <- cutree(dend_cpall_gf_op, k = 2)
cluster_counts_2 <- table(cluster_assignments_2)
print(cluster_counts_2)
# 4 clusters
dend_4clusters <- color_branches(dend_cpall_gf_op, k = 4, groupLabels=T)
plot(stats::dendrapply(dend_4clusters, noLabel))

# 5 clusters
dend_5clusters <- color_branches(dend_cpall_gf_op, k = 5, groupLabels=T)
plot(stats::dendrapply(dend_5clusters, noLabel))
cluster_assignments_5 <- cutree(dend_cpall_gf_op, k = 5)
cluster_counts_5 <- table(cluster_assignments_5)
print(cluster_counts_5)

# 6 clusters
dend_6clusters <- color_branches(dend_cpall_gf_op, k = 6, groupLabels=T)
plot(stats::dendrapply(dend_6clusters, noLabel))
cluster_assignments_6 <- cutree(dend_cpall_gf_op, k = 6)
cluster_counts_6 <- table(cluster_assignments_6)
print(cluster_counts_6)

# 7 clusters
dend_7clusters <- color_branches(dend_cpall_gf_op, k = 7, groupLabels=T)
plot(stats::dendrapply(dend_7clusters, noLabel))
cluster_assignments_7 <- cutree(dend_cpall_gf_op, k = 7)
cluster_counts_7 <- table(cluster_assignments_7)
print(cluster_counts_7) # only 7 in one group 

# 8 clusters
dend_8clusters <- color_branches(dend_cpall_gf_op, k = 8, groupLabels=T)
plot(stats::dendrapply(dend_8clusters, noLabel))
cluster_assignments_8 <- cutree(dend, k = 8)
cluster_counts_8 <- table(cluster_assignments_8)
print(cluster_counts_8)

# 12 clusters
dend_12clusters <- color_branches(dend_cpall_gf_op, k = 12, groupLabels=T)
plot(stats::dendrapply(dend_12clusters, noLabel))
# check number per cluster
cluster_assignments_12 <- cutree(dend, k = 12)
cluster_counts_12 <- table(cluster_assignments_12)
print(cluster_counts_12)


# 6 clusters appears optimal

# k = 6
# 6 clusters
dend_6clusters <- color_branches(dend_cpall_gf_op, k = 6, groupLabels=T)
plot(stats::dendrapply(dend_6clusters, noLabel))
cluster_assignments_6 <- cutree(dend_cpall_gf_op, k = 6)
cluster_counts_6 <- table(cluster_assignments_6)
print(cluster_counts_6)

# The function 'cuttree' is used to cut the tree at k = 4 as determined by the indices (see peak in CH index)
groups_cpall_gf_op_c6 <- cutree(hc_cpall_gf_op_clust, k=6)
ps_RA_cpall_gf_op@sam_data$cluster <- groups_cpall_gf_op_c6[order(rownames(ps_RA_cpall_gf_op@sam_data))]
ps_RA_cpall_gf_op@sam_data$cluster <- ps_RA_cpall_gf_op@sam_data$cluster %>% as.character()

# Determine the top 3 ASVs for each cluster
otu_cpall_gf_op <- as(otu_table(ps_RA_cpall_gf_op), "matrix")
if (taxa_are_rows(ps_RA_cpall_gf_op)) {
  otu_cpall_gf_op <- t(otu_cpall_gf_op)  # Ensure ASVs are columns, samples are rows
}

# Extract sample metadata with cluster information
sample_data_cpall_gf_op <- data.frame(ps_RA_cpall_gf_op@sam_data)
# Combine the OTU table with the sample cluster data
otu_cpall_gf_op_with_clusters <- cbind(cluster = sample_data_cpall_gf_op$cluster, otu_cpall_gf_op)
otu_cpall_gf_op_with_clusters <- as.data.frame(otu_cpall_gf_op_with_clusters)
otu_cpall_gf_op_with_clusters$cluster <- as.factor(otu_cpall_gf_op_with_clusters$cluster)
# Convert all ASV abundances to numeric
otu_cpall_gf_op_with_clusters[-1] <- lapply(otu_cpall_gf_op_with_clusters[-1], as.numeric)
# Sum ASV abundances for each cluster
asv_sum_by_cluster_cpall_gf_op <- otu_cpall_gf_op_with_clusters %>%
  group_by(cluster) %>%
  summarise(across(where(is.numeric), sum, na.rm = TRUE))
# Convert back to data frame for further processing
asv_sum_by_cluster_cpall_gf_op <- as.data.frame(asv_sum_by_cluster_cpall_gf_op)
# Find the top 3 most abundant ASVs in each cluster and their percentage
top_3_asvs_cpall_gf_op <- apply(asv_sum_by_cluster_cpall_gf_op[, -1], 1, function(x) {
  # Get total abundance in the cluster for calculating percentages
  total_abundance_cpall_gf_op <- sum(x, na.rm = TRUE)
  # Get names and values of the top 3 ASVs
  top_3_indices_cpall_gf_op <- order(x, decreasing = TRUE)[1:3]
  top_3_asv_names_cpall_gf_op <- names(x)[top_3_indices_cpall_gf_op]
  top_3_asv_values_cpall_gf_op <- x[top_3_indices_cpall_gf_op]
  # Calculate percentages
  top_3_asv_percentages_cpall_gf_op <- (top_3_asv_values_cpall_gf_op / total_abundance_cpall_gf_op) * 100
  # Combine ASV names and percentages into a string for each cluster
  result <- paste0(top_3_asv_names_cpall_gf_op, ": ", round(top_3_asv_percentages_cpall_gf_op, 2), "%", collapse = "; ")
  return(result)
})

# Combine results with cluster information
top_3_asvs_df_cpall_gf_op <- data.frame(cluster = asv_sum_by_cluster_cpall_gf_op$cluster, Top_3_ASVs = top_3_asvs_cpall_gf_op)
# Display the top 3 ASVs for each cluster along with their percentages
print(top_3_asvs_df_cpall_gf_op)

#### Rename clusters ####
# If an ASV is >40% of the total abundance in a cluster: Name the cluster after that ASV only, as it is the dominant contributor.
# If the top ASV is between 20-40% of the total abundance: Use the two most abundant ASVs to name the cluster.
# If the top ASV is <20% of the total abundance: Use the top three ASVs to name the cluster, as none of the ASVs dominate significantly.

get_cluster_name <- function(top_asvs_string) {
  asv_info <- strsplit(top_asvs_string, "; ")[[1]]
  asv_names <- sapply(asv_info, function(x) strsplit(x, ": ")[[1]][1])
  asv_percentages <- as.numeric(sapply(asv_info, function(x) sub("%", "", strsplit(x, ": ")[[1]][2])))
  
  if (asv_percentages[1] > 40) {
    return(paste0(asv_names[1], "-dominated cluster"))
  } else if (asv_percentages[1] > 20) {
    return(paste0(asv_names[1], " and ", asv_names[2], "-dominated cluster"))
  } else {
    return(paste0(asv_names[1], ", ", asv_names[2], ", and ", asv_names[3], "-dominated cluster"))
  }
}

# Rename based on these rules
top_3_asvs_df_cpall_gf_op$Cluster_Name <- sapply(top_3_asvs_df_cpall_gf_op$Top_3_ASVs, get_cluster_name)

# [1] "Streptococcus_4, Prevotella_histicola_12, and Veillonella_6-dominated cluster"                      
# [2] "Veillonella_6, Streptococcus_4, and Prevotella_melaninogenica_11-dominated cluster"                 
# [3] "Streptococcus_4 and Veillonella_6-dominated cluster"                                                
# [4] "Streptococcus_8, Neisseria_13, and Haemophilus_14-dominated cluster"                                
# [5] "Streptococcus_8 and Gemella_27-dominated cluster"                                                   
# [6] "Fusobacterium_nucleatum_72, Porphyromonas_endodontalis_76, and Prevotellaceae_128-dominated cluster"

# Shorten the names made above for plotting 
# Define the new cluster names in the same order as the original clusters
new_cluster_names_cpall_gf_op <- c(
  "Strep(4)/Prev(12)/Veill(6) clust",
  "Veill(6)/Strep(4)/Prev(11) clust",
  "Strep(4)/Veill(6) clust",
  "Strep(8)/Neis(13)/Hae(14) clust",
  "Strep(8)/Gem(27) clust",
  "Fuso(72)/Por(76)/Prev(128) clust"
)

# Assign the new names to 'Cluster_Name' in 'top_3_asvs_df'
top_3_asvs_df_cpall_gf_op$Cluster_Name <- new_cluster_names_cpall_gf_op

# Update the clusters in the sample data to use the new names
ps_RA_cpall_gf_op@sam_data$cluster <- top_3_asvs_df_cpall_gf_op$Cluster_Name[match(ps_RA_cpall_gf_op@sam_data$cluster, top_3_asvs_df_cpall_gf_op$cluster)]
# Convert to character
ps_RA_cpall_gf_op@sam_data$cluster <- as.character(ps_RA_cpall_gf_op@sam_data$cluster)

# Count the number of samples in each cluster
cluster_counts_cpall_gf_op <- as.data.frame(table(ps_RA_cpall_gf_op@sam_data$cluster))
colnames(cluster_counts_cpall_gf_op) <- c("Cluster", "Count")

# Calculate the relative proportions of each cluster
cluster_counts_cpall_gf_op$Proportion <- cluster_counts_cpall_gf_op$Count / sum(cluster_counts_cpall_gf_op$Count)

write.csv(cluster_counts_cpall_gf_op, "../Output/Cluster_analysis/CPall_GF_OP/cluster_counts_cpall_gf_op.csv")

# Create the plot with geom_bar for vertical stacking
bar_clusters_cpall_gf_op <- ggplot(data = cluster_counts_cpall_gf_op, aes(x = Cluster, y = (Proportion*100), fill = Cluster)) +
  geom_bar(stat = "identity") +  # Use stat = "identity" to directly use Proportion
  labs(title = "Bar Plot of Clusters in Control Population and Goat farmers",
       x = "Clusters",            # X-axis now represents clusters
       y = "% of samples",          # Y-axis represents proportions
       fill = "Cluster") +
  scale_fill_manual(values = c(paletteer_d("pals::stepped")[c(13,20,10,16,1,18)])) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),      # Remove x-axis labels if needed
        axis.ticks.x = element_blank(),     # Remove x-axis ticks if needed
        legend.position = "right")

bar_clusters_cpall_gf_op
ggsave("../Output/Cluster_analysis/CPall_GF_OP/Bar_plot_cluster_proportions_clusters.svg", bar_clusters_cpall_gf_op, width = 8, height = 5)

```
#### Visualisations for manuscript
```{r}
dendro_cpall_gf_op <- create_dendro_gg(hc_cpall_gf_op_clust, size = 0.15)

otu_hm_cpall_gf_op <- as(otu_table(ps_RA_cpall_gf_op), "matrix")
# Order the otu data based on the mean RA across samples
otu_hm_cpall_gf_op_order <- otu_hm_cpall_gf_op[order(rowMeans(otu_hm_cpall_gf_op), decreasing = T)[1:45], hc_cpall_gf_op_clust$order]
# Order the metadata according to the clustering order
meta_hm_cpall_gf_op_order <- ps_RA_cpall_gf_op %>% meta_to_df()
meta_hm_cpall_gf_op_order <- meta_hm_cpall_gf_op_order[hc_cpall_gf_op_clust$order,]

# Confirm that the order of samples in the otu data matches the order of samples in the cluster plot
all(colnames(otu_hm_cpall_gf_op_order) == hc_cpall_gf_op_clust$labels[hc_cpall_gf_op_clust$order])

hm_cpall_gf_op_data <- prep_hm_data(otu_hm_cpall_gf_op_order)

# Overall heatmap
hm_cpall_gf <- hm_cpall_gf_op_data %>%
  ggplot(aes(x = sample_id, y = OTU, fill = RA)) +
  geom_tile() +
  scale_fill_gradientn(name="Relative abundance", 
                       colors = carto_pal(7, "BurgYl"), 
                       na.value = "white", 
                       guide = guide_colorbar(title.position = "top", title.hjust = 0.5)) +
  theme_grey(base_size = 10) + 
  theme(axis.text.x = element_blank(), 
        axis.text.y = element_markdown(size = 10), # Uniform y-axis text size
        axis.ticks.x = element_blank(), 
        legend.position = "bottom",
        legend.key.height = grid::unit(0.2, "cm"),
        legend.key.width = grid::unit(0.8, "cm"),
        legend.text = element_text(size = 10),     # Uniform legend text size
        plot.background = element_blank()) +
  xlab("Sample") + 
  ylab("ASV")
hm_cpall_gf

# Cluster plot
meta_hm_cpall_gf_op_order$sample_id <- factor(meta_hm_cpall_gf_op_order$sample_id, levels = unique(meta_hm_cpall_gf_op_order$sample_id[order(meta_hm_cpall_gf_op_order$cluster)]))


hm_cluster_cpall_gf_op <- meta_hm_cpall_gf_op_order %>%
  ggplot(aes(x = sample_id, y = "Cluster", fill = cluster)) +
  theme_void() + 
  geom_tile() + 
  scale_fill_manual(values = c(paletteer_d("pals::stepped")[c(13,15,12,10,1,3,19,20,5,7,23)])) + 
  labs(fill = "Cluster") + 
  theme(axis.text.y = element_text(size = 10), # Uniform y-axis text size
        axis.ticks.length.y = unit(.18, "cm"),
        legend.direction = "vertical", 
        legend.box = "vertical",
        legend.key.size = unit(0.8, "lines"),
        legend.text = element_text(size = 10))    # Uniform legend text size
hm_cluster_cpall_gf_op

# Population plot 
hm_pop_cpall_gf_op <- meta_hm_cpall_gf_op_order %>%
  ggplot(aes(x = sample_id, y = "Population", fill = population)) +
  theme_void() + 
  geom_tile() + 
  scale_fill_brewer(palette = "Set2") + 
  labs(fill = "Population") + 
  theme(axis.text.y = element_text(size = 10), # Uniform y-axis text size
        axis.ticks.length.y = unit(.18, "cm"),
        legend.direction = "vertical", 
        legend.box = "vertical",
        legend.key.size = unit(0.8, "lines"),
        legend.text = element_text(size = 10))   # Uniform legend text size
hm_pop_cpall_gf_op

# Prevalence plot
p_prev_cpall_gf_op <- ggplot(prev_cpall_gf_op, aes(x = Prevalence, y = Taxa)) +
  geom_bar(stat = "identity", fill = "azure4", width = 0.5) +
  labs(x = "Prevalence") +
  theme_minimal() + 
  theme(axis.text.y = element_blank(), 
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x = element_text(size = 10),   # Uniform x-axis text size
        legend.text = element_text(size = 10)) + # Uniform legend text size
  scale_x_continuous(breaks = c(0, 0.5, 1),
                     labels = scales::percent_format())
p_prev_cpall_gf_op


# Make patchwork of plot
layout_cp_gf <- "
AAAAAA#
AAAAAA#
AAAAAA#
BBBBBB#
CCCCCC#
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
DDDDDDE
"

dendro_cpall_gf_op$plot + hm_pop_cpall_gf_op + hm_cluster_cpall_gf_op + hm_cpall_gf + p_prev_cpall_gf_op + plot_layout(design = layout_cp_gf, guides = "collect") & theme(legend.position = 'bottom')

ggsave("../Output/Cluster_analysis/CPall_GF_OP/heatmap_cluster_cpall_gf_op.svg", height = 10, width = 8)
ggsave("../Output/Cluster_analysis/CPall_GF_OP/heatmap_cluster_cpall_gf_op.png", height = 10, width = 8)


```

# Control population only
## NP
### Correlation analysis of metadata
```{r}
sample_data_df_cp_np <- data.frame(ps_RA_cp_np@sam_data)

# Extract the variables into a new data frame for simplicity
variables <- sample_data_df_cp_np[, c("KRD_nPoultryWghtDist.3000m.sum", 
                                      "KRD_nCowsWghtDist.3000m.sum", 
                                      "KRD_nGoatsWghtDist.3000m.sum", 
                                      "KRD_nPigsWghtDist.3000m.sum")]


# Calculate the correlation matrix and p-values
corr_result <- psych::corr.test(variables)
corr_matrix <- corr_result$r    # Correlation matrix
p_matrix <- corr_result$p       # p-value matrix

# Convert correlation matrix and p-value matrix to long format
corr_long <- melt(corr_matrix)
p_long <- melt(p_matrix)

# Merge correlation and p-value matrices into one data frame
corr_long$p_value <- p_long$value

# Create labels based on significance levels
corr_long$label <- ifelse(corr_long$p_value < 0.001, "***",
                          ifelse(corr_long$p_value < 0.01, "**",
                                 ifelse(corr_long$p_value < 0.05, "*", "NS")))


# Only keep the upper triangle (excluding self-comparisons)
corr_long <- corr_long %>% 
  filter(as.numeric(Var1) < as.numeric(Var2))

# Plot the half-matrix heatmap with correlation coefficients and significance stars as labels
ggplot(corr_long, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "#6D9EC1", high = "#E46726", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  geom_text(aes(label = paste0(round(value, 2), "\n", label)), color = "black", size = 4) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(hjust = 1),
        axis.title.x = element_blank(),
        axis.title.y = element_blank()) +
  ggtitle("Correlation Matrix with Significance Stars")



# Fit a logistic regression model for one of the clusters
logit_model <- glm(cluster=="Cor(3)/Staph(2) clust" ~ KRD_nPoultryWghtDist.3000m.sum + KRD_nCowsWghtDist.3000m.sum + KRD_nGoatsWghtDist.3000m.sum + KRD_nPigsWghtDist.3000m.sum +age +gender +smoked_ever + sampling_season, data = sample_data_df_cp_np, family = binomial)
# Calculate the Variance Inflation Factor (VIF)
vif_results <- vif(logit_model)

# Display VIF results
print(vif_results) # None of the GVIF values are >2, can we can go ahead with the distance-weighted metrics together in a multivariable model


# Check distribution of livestock exposure proxies
boxplot(sample_data_cp_np$ecoli_RF_preds)
boxplot(sample_data_cp_np$staph_RF_preds)
boxplot(sample_data_cp_np$tetw_RF_preds)
boxplot(sample_data_cp_np$meca_RF_preds)


```
### Cluster count and visualisation 
```{r}
# First, we remove the GF samples from the phyloseq to include only the CPs
ps_RA_cp_np <- subset_samples(ps_RA_cpall_gf_np, population != "GF")
ps_RA_cp_np <- prune_taxa(taxa_sums(ps_RA_cp_np) > 0, ps_RA_cp_np)

# Check number in each cluster in the CP NP samples
table(ps_RA_cp_np@sam_data$cluster)


# Create the plot with geom_bar for vertical stacking
# Count the number of samples in each cluster
cluster_counts_cp_np <- as.data.frame(table(ps_RA_cp_np@sam_data$cluster))
colnames(cluster_counts_cp_np) <- c("Cluster", "Count")
# Calculate the relative proportions of each cluster
cluster_counts_cp_np$Proportion <- cluster_counts_cp_np$Count / sum(cluster_counts_cp_np$Count)
write.csv(cluster_counts_cp_np, "../Output/Cluster_analysis/CP_NP/Cluster_counts_proportions_cp_np.csv")
# Bar plot of cluster numbers
bar_clusters_cp_np <- ggplot(data = cluster_counts_cp_np, aes(x = Cluster, y = (Proportion*100), fill = Cluster)) +
  geom_bar(stat = "identity") +  # Use stat = "identity" to directly use Proportion
  labs(title = "Bar Plot of Clusters in Control Population",
       x = "Clusters",            # X-axis now represents clusters
       y = "% of samples",          # Y-axis represents proportions
       fill = "Cluster") +
  scale_fill_manual(values = c(paletteer_d("pals::stepped")[c(13,15,12,10,1,3,19,20,5,7,23)])) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),      # Remove x-axis labels if needed
        axis.ticks.x = element_blank(),     # Remove x-axis ticks if needed
        legend.position = "right")

bar_clusters_cp_np
ggsave("../Output/Cluster_analysis/CP_NP/Bar_plot_cluster_proportions_clusters.svg", bar_clusters_cp_np, width = 8, height = 5)
```
### Logistic regression analysis
```{r}
# Convert sample data to a dataframe
sample_data_df_cp_np <- data.frame(ps_RA_cp_np@sam_data)

#### Logistic regression for continuous variables ####
# We conduct logistic regression to determine whether the probability of belonging to a specific cluster increases with higher values of each continuous variable.
# For RF-modelled concentrations, we use a multivariable logistic regression model per exposure agent i.e. cluster1 ~ e.coli + age + gender + season + smoking
# For distance-based variables, we test them all together in one multivariable logistic regression model i.e. cluster1 ~ goats+ cows + pigs + poultry + age + gender + season + smoking


# Since Logistic regression requires sufficient counts in each outcome category to generate reliable and stable parameter estimates, we will exclude some of the clusters with low counts - anything with below 10 counts (out of the 1000 CPs)
# Calculate cluster counts
cluster_counts <- table(sample_data_df_cp_np$cluster)
# Identify clusters with counts >= 10
clusters_to_keep <- names(cluster_counts[cluster_counts >= 10])
# Filter the dataset to retain only rows with clusters in clusters_to_keep
sample_data_df_cp_np <- sample_data_df_cp_np %>%
  filter(cluster %in% clusters_to_keep)

# Define the columns where we want to replace NA values with 0
columns_to_replace_na <- c("KRD_nGoatsWghtDist.3000m.sum", 
                           "KRD_nCowsWghtDist.3000m.sum", 
                           "KRD_nPoultryWghtDist.3000m.sum", 
                           "KRD_nPigsWghtDist.3000m.sum")

# Replace NAs with 0 for the specified columns
for (column in columns_to_replace_na) {
  sample_data_df_cp_np[[column]] <- replace_na(sample_data_df_cp_np[[column]], 0)
}

# Initialize an empty data frame to store logistic regression results
logistic_results_df_cp_np <- data.frame()

# Define the additional variables for the multivariable model
additional_vars <- c("age", "gender", "smoked_ever", "sampling_season")

# Convert categorical data to factors and set reference levels
sample_data_df_cp_np$gender <- relevel(as.factor(sample_data_df_cp_np$gender), ref = "0") 
sample_data_df_cp_np$smoked_ever <- relevel(as.factor(sample_data_df_cp_np$smoked_ever), ref = "0")  
sample_data_df_cp_np$sampling_season <- relevel(as.factor(sample_data_df_cp_np$sampling_season), ref = "Summer")  

# Set continuous variables based on columns_to_replace_na
continuous_vars <- columns_to_replace_na

# Loop through each cluster
for (clust in unique(sample_data_df_cp_np$cluster)) {
  # Create a binary outcome for each cluster (1 if sample is in the cluster, 0 otherwise)
  sample_data_df_cp_np$in_cluster <- ifelse(sample_data_df_cp_np$cluster == clust, 1, 0)
  # Fit the multivariable logistic regression model for the continuous variables
  formula_multivariable <- as.formula(paste("in_cluster ~", paste(c(continuous_vars, additional_vars), collapse = " + ")))
  model_multivariable <- glm(formula_multivariable, 
                             data = sample_data_df_cp_np, 
                             family = binomial)
  # Extract summary statistics
  summary_stats <- as.data.frame(summary(model_multivariable)$coefficients)
  # Add cluster and variable names for clarity
  summary_stats$Cluster <- clust
  summary_stats$Variable <- rownames(summary_stats)
  # Append to the results data frame
  logistic_results_df_cp_np <- rbind(logistic_results_df_cp_np, summary_stats)

  # Run separate models for each RF predictor
  for (rf_var in c("ecoli_RF_preds", "staph_RF_preds", "tetw_RF_preds", "meca_RF_preds")) {
    rf_formula <- as.formula(paste("in_cluster ~", rf_var, "+ age + gender + smoked_ever + sampling_season"))
    
    model_rf <- glm(rf_formula, 
                    data = sample_data_df_cp_np, 
                    family = binomial)
    
    # Extract summary statistics
    rf_summary_stats <- as.data.frame(summary(model_rf)$coefficients)
    # Add cluster and variable names for clarity
    rf_summary_stats$Cluster <- clust
    rf_summary_stats$Variable <- rf_var
    # Append to the results data frame
    logistic_results_df_cp_np <- rbind(logistic_results_df_cp_np, rf_summary_stats)
  }
}

# Rearrange columns to show Cluster and Variable first (optional)
logistic_results_df_cp_np <- logistic_results_df_cp_np %>%
  select(Cluster, Variable, everything())

# Print save the results
print(logistic_results_df_cp_np)

# Add a new column "Covariate" to logistic_results_df_cp_np by removing numbers from the end of each Variable name
logistic_results_df_cp_np$Covariate <- gsub("[0-9]+$", "", rownames(logistic_results_df_cp_np))

# Apply the BH adjustment globally across the entire set of p values from all models (for all covariates and not separately within each model)
logistic_results_df_cp_np$BH_adjusted_pvalue_global <- p.adjust(logistic_results_df_cp_np$`Pr(>|z|)`, method = "BH")

# Filter results and retain only rows of interest, then arrange columns for readability
# Define the covariates to filter by
covariates_to_keep <- c("ecoli_RF_preds", "staph_RF_preds", "tetw_RF_preds", "meca_RF_preds", 
                        "KRD_nGoatsWghtDist.3000m.sum", "KRD_nCowsWghtDist.3000m.sum", 
                        "KRD_nPoultryWghtDist.3000m.sum", "KRD_nPigsWghtDist.3000m.sum")

# Filter for rows where the Covariate column matches the specified covariates
filtered_results_df_cp_np <- logistic_results_df_cp_np %>%
  filter(Covariate %in% covariates_to_keep) %>%
  select(Cluster, Variable, everything(), BH_adjusted_pvalue_global)

# Print the filtered results
print(filtered_results_df_cp_np)

# Print and/or save the globally adjusted results
print(filtered_results_df_cp_np)
write.csv(filtered_results_df_cp_np, "../Output/Cluster_analysis/CP_NP/Logistic_regression_results_cp_np_all_adjusted.csv")

# # Test BH-adjustment on only covariates interested in
# # Define the covariates to adjust p-values for
# covariates_to_adjust <- c("ecoli_RF_preds", "staph_RF_preds", "tetw_RF_preds", "meca_RF_preds", 
#                           "KRD_nGoatsWghtDist.3000m.sum", "KRD_nCowsWghtDist.3000m.sum", 
#                           "KRD_nPoultryWghtDist.3000m.sum", "KRD_nPigsWghtDist.3000m.sum")
# 
# # Apply the BH adjustment globally across all p-values in the full dataset
# logistic_results_df_cp_np$BH_adjusted_pvalue_global <- p.adjust(logistic_results_df_cp_np$`Pr(>|z|)`, method = "BH")
# 
# # Filter the dataset to include only the specified covariates
# filtered_covariates_df <- logistic_results_df_cp_np %>%
#   filter(Covariate %in% covariates_to_adjust)
# 
# # Apply the BH adjustment locally to the filtered covariates
# filtered_covariates_df$BH_adjusted_pvalue_local <- p.adjust(filtered_covariates_df$`Pr(>|z|)`, method = "BH")
# 
# # Compare globally and locally adjusted p-values
# filtered_covariates_df <- filtered_covariates_df %>%
#   select(Cluster, Covariate, `Pr(>|z|)`, BH_adjusted_pvalue_global, BH_adjusted_pvalue_local)
# 
# # Print the comparison of adjusted p-values
# print(filtered_covariates_df)
# 
# # Save the locally adjusted results to a CSV file
# write.csv(filtered_covariates_df, "../Output/Cluster_analysis/CP_NP/Logistic_regression_results_cp_np_filtered_adjusted.csv")
# 
# 
# 




# This logistic regression analysis Without a reference category, means that we get estimates for the "odds ratio" for each cluster in relation to the rest of the clusters, rather than a direct comparison between a chosen "reference" cluster and all others.
# Without a reference group, the odds ratios in these models represent the likelihood of being in a given cluster vs. any other cluster combined, which can be harder to interpret in context





#### With Dolo(1) ref category ####
# Select 'reference' cluster - by doing this the coefficients for the other clusters reflect how much more or less likely it is to belong to a specific cluster in comparison to the reference group. This makes the results easier to interpret.
# Logistic regression models with a reference category tend to be more stable, as the interpretation of the odds ratios is constrained in a meaningful way, rather than comparing each group against the entire dataset.

sample_data_df_cp_np_ref <- sample_data_df_cp_np
# Since Logistic regression requires sufficient counts in each outcome category to generate reliable and stable parameter estimates, we will exclude some of the clusters with low counts - anything with below 10 counts (out of the 1000 CPs)
# Calculate cluster counts
cluster_counts <- table(sample_data_df_cp_np_ref$cluster)
# Identify clusters with counts >= 10
clusters_to_keep <- names(cluster_counts[cluster_counts >= 10])
# Filter the dataset to retain only rows with clusters in clusters_to_keep
sample_data_df_cp_np_ref <- sample_data_df_cp_np_ref %>%
  filter(cluster %in% clusters_to_keep)

# Define the columns where we want to replace NA values with 0
columns_to_replace_na <- c("KRD_nGoatsWghtDist.3000m.sum", 
                           "KRD_nCowsWghtDist.3000m.sum", 
                           "KRD_nPoultryWghtDist.3000m.sum", 
                           "KRD_nPigsWghtDist.3000m.sum")

# Replace NAs with 0 for the specified columns
for (column in columns_to_replace_na) {
  sample_data_df_cp_np_ref[[column]] <- replace_na(sample_data_df_cp_np_ref[[column]], 0)
}

# Initialize an empty data frame to store logistic regression results
logistic_results_df_cp_np_ref <- data.frame()
# Define the additional variables for the multivariable model
additional_vars <- c("age", "gender", "smoked_ever", "sampling_season")

# Convert categorical data to factors and set reference levels
# Set a reference category for the cluster variable - Dolo(1) clust is the most common and represents a healthy nasal microbiome- this cluster is composed of Dolosigranulum_pigrum_1: 43.93%; Corynebacterium_3: 16.05%; Corynebacterium_7: 15.45% 
# Convert categorical data to factors and set reference levels
sample_data_df_cp_np_ref$gender <- relevel(as.factor(sample_data_df_cp_np_ref$gender), ref = "0") 
sample_data_df_cp_np_ref$smoked_ever <- relevel(as.factor(sample_data_df_cp_np_ref$smoked_ever), ref = "0")  
sample_data_df_cp_np_ref$sampling_season <- relevel(as.factor(sample_data_df_cp_np_ref$sampling_season), ref = "Summer")

# Loop through each cluster (except the reference cluster)
for (clust in setdiff(unique(sample_data_df_cp_np_ref$cluster), "Dolo(1) clust")) {
  # Create a binary outcome for each cluster (1 if sample is in the cluster, 0 otherwise)
  sample_data_df_cp_np_ref$in_cluster <- ifelse(sample_data_df_cp_np_ref$cluster == clust, 1, 0)
  
  # Fit the multivariable logistic regression model for the continuous variables
  formula_multivariable <- as.formula(paste("in_cluster ~", paste(c(continuous_vars, additional_vars), collapse = " + ")))
  model_multivariable <- glm(formula_multivariable, 
                             data = sample_data_df_cp_np_ref, 
                             family = binomial)
  
  # Extract summary statistics
  summary_stats <- as.data.frame(summary(model_multivariable)$coefficients)
  
  # Add cluster and variable names for clarity
  summary_stats$Cluster <- clust
  summary_stats$Variable <- rownames(summary_stats)
  
  # Append to the results data frame
  logistic_results_df_cp_np_ref <- rbind(logistic_results_df_cp_np_ref, summary_stats)

  # Run separate models for each RF predictor (ecoli, staph, etc.)
  for (rf_var in c("ecoli_RF_preds", "staph_RF_preds", "tetw_RF_preds", "meca_RF_preds")) {
    rf_formula <- as.formula(paste("in_cluster ~", rf_var, "+ age + gender + smoked_ever + sampling_season"))
    
    model_rf <- glm(rf_formula, 
                    data = sample_data_df_cp_np_ref, 
                    family = binomial)
    
    # Extract summary statistics
    rf_summary_stats <- as.data.frame(summary(model_rf)$coefficients)
    
    # Add cluster and variable names for clarity
    rf_summary_stats$Cluster <- clust
    rf_summary_stats$Variable <- rf_var
    
    # Append to the results data frame
    logistic_results_df_cp_np_ref <- rbind(logistic_results_df_cp_np_ref, rf_summary_stats)
  }
}

# Rearrange columns to show Cluster and Variable first (optional)
logistic_results_df_cp_np_ref <- logistic_results_df_cp_np_ref %>%
  select(Cluster, Variable, everything())

# Print results
print(logistic_results_df_cp_np_ref)

# Add a new column "Covariate" to logistic_results_df_cp_np by removing numbers from the end of each Variable name
logistic_results_df_cp_np_ref$Covariate <- gsub("[0-9]+$", "", rownames(logistic_results_df_cp_np_ref))

# Apply the BH adjustment globally across the entire set of p values from all models (not separately within each model)
logistic_results_df_cp_np_ref$BH_adjusted_pvalue <- p.adjust(logistic_results_df_cp_np_ref$`Pr(>|z|)`, method = "BH")

# Filter results and retain only rows of interest, then arrange columns for readability
# Define the covariates to filter by
covariates_to_keep <- c("ecoli_RF_preds", "staph_RF_preds", "tetw_RF_preds", "meca_RF_preds", 
                        "KRD_nGoatsWghtDist.3000m.sum", "KRD_nCowsWghtDist.3000m.sum", 
                        "KRD_nPoultryWghtDist.3000m.sum", "KRD_nPigsWghtDist.3000m.sum")

# Filter for rows where the Covariate column matches the specified covariates
filtered_results_df_cp_np_ref <- logistic_results_df_cp_np_ref %>%
  filter(Covariate %in% covariates_to_keep) %>%
  select(Cluster, Variable, everything(), BH_adjusted_pvalue)

# Print the filtered results
print(filtered_results_df_cp_np_ref)

# Print and/or save the globally adjusted results
print(filtered_results_df_cp_np_ref)
write.csv(filtered_results_df_cp_np_ref, "../Output/Cluster_analysis/CP_NP/Logistic_regression_results_cp_np_all_adjusted_with ref.csv")


```
### Heatmap of odds ratios
```{r}
#### No reference cluster ####
# Present the Odds ratio instead of the estimate - this tells us how the odds of belonging to a specific cluster change with each unit increase in the predictor variable. 
# only include columns of interest
filtered_results_df_cp_np_plot <- filtered_results_df_cp_np %>%
  select(Cluster, Variable, Estimate, BH_adjusted_pvalue, `Std. Error`)
filtered_results_df_cp_np_plot$Estimate
# Calculate Odds Ratios and Confidence Intervals
filtered_results_df_cp_np_plot <- filtered_results_df_cp_np_plot %>%
  mutate(
    OR = exp(Estimate),
    Lower_CI = exp(Estimate - 1.96 * `Std. Error`),
    Upper_CI = exp(Estimate + 1.96 * `Std. Error`)
  )
filtered_results_df_cp_np_plot$OR
# Reorder the variables for the plot
filtered_results_df_cp_np_plot$Variable <- factor(filtered_results_df_cp_np_plot$Variable,
  levels = c("KRD_nCowsWghtDist.3000m.sum","KRD_nPoultryWghtDist.3000m.sum","KRD_nGoatsWghtDist.3000m.sum","KRD_nPigsWghtDist.3000m.sum","meca_RF_preds","tetw_RF_preds","staph_RF_preds","ecoli_RF_preds"))


filtered_results_df_cp_np_plot <- filtered_results_df_cp_np_plot %>%
  mutate(Variable = dplyr::recode(Variable,
    "ecoli_RF_preds" = "RF-modelled E. coli exposure",
    "staph_RF_preds" = "RF-modelled Staphylococcus spp. exposure",
    "tetw_RF_preds" = "RF-modelled tetW ARG exposure",
    "meca_RF_preds" = "RF-modelled mecA ARG exposure",
    "KRD_nPigsWghtDist.3000m.sum" = "Distance weighted number of pigs in 3000m",
    "KRD_nGoatsWghtDist.3000m.sum" = "Distance weighted number of goats in 3000m",
    "KRD_nPoultryWghtDist.3000m.sum" = "Distance weighted number of chickens in 3000m",
    "KRD_nCowsWghtDist.3000m.sum" = "Distance weighted number of cattle in 3000m"
  ))



filtered_results_df_cp_np_plot <- filtered_results_df_cp_np_plot %>%
  mutate(Significance = case_when(
    BH_adjusted_pvalue < 0.05 ~ "***",
    BH_adjusted_pvalue < 0.1 ~ "**",
    BH_adjusted_pvalue < 0.25 ~ "*",
    TRUE ~ ""
  ))
filtered_results_df_cp_np_plot$OR

# Create heatmap data as before
heatmap_data_cp_np <- filtered_results_df_cp_np_plot %>%
  select(Variable, Cluster, OR, Significance) %>%
  dcast(Variable ~ Cluster, value.var = "OR")  # Reshape data for heatmap

# Convert to long format for ggplot
heatmap_long_cp_np <- melt(heatmap_data_cp_np, id.vars = "Variable", variable.name = "Cluster", value.name = "OR")

# Merge significance markers back into the long format dataframe
heatmap_long_cp_np <- heatmap_long_cp_np %>%
  left_join(filtered_results_df_cp_np_plot %>% select(Variable, Cluster, Significance), by = c("Variable", "Cluster"))

# Step 3: Create the heatmap with significance markers
heatmap_residential_expo_cp_np <- ggplot(heatmap_long_cp_np, aes(x = Cluster, y = Variable, fill = OR)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = carto_pal(7, "Geyser")[1], 
    mid = carto_pal(7, "Geyser")[4], 
    high = carto_pal(7, "Geyser")[7], 
    midpoint = 1,
    name = "Odds Ratio"
  ) +
  labs(
    title = "Residential livestock exposure on NP clusters\n Control population - no reference cluster",
    x = "Cluster",
    y = "Variables"
  ) +
  scale_y_discrete(labels = c(
    "RF-modelled E. coli exposure" = "RF-modelled *E. coli* exposure",
    "RF-modelled Staphylococcus spp. exposure" = "RF-modelled *Staphylococcus* spp. exposure",
    "RF-modelled tetW ARG exposure" = "RF-modelled *tetW* ARG exposure",
    "RF-modelled mecA ARG exposure" = "RF-modelled *mecA* ARG exposure",
    "Distance weighted number of pigs in 3000m" = "Distance weighted number of pigs in 3000m",
    "Distance weighted number of goats in 3000m" = "Distance weighted number of goats in 3000m",
    "Distance weighted number of chickens in 3000m" = "Distance weighted number of chickens in 3000m",
    "Distance weighted number of cattle in 3000m" = "Distance weighted number of cattle in 3000m"
  )) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5),
    axis.text.y = element_markdown()  # Enable markdown for y-axis labels
  ) +
  geom_text(aes(label = Significance), color = "black", size = 5, vjust = 0.5) 

heatmap_residential_expo_cp_np
# Save the heatmap
ggsave("../Output/Cluster_analysis/CP_NP/Residential_livestock_expo_heatmap.svg", heatmap_residential_expo_cp_np, width = 6, height = 5)


#### With Dolo(1) ref category ####
# Present the Odds ratio instead of the estimate - this tells us how the odds of belonging to a specific cluster change with each unit increase in the predictor variable. 
# only include columns of interest
filtered_results_df_cp_np_ref_plot <- filtered_results_df_cp_np_ref %>%
  select(Cluster, Variable, Estimate, BH_adjusted_pvalue, `Std. Error`)
filtered_results_df_cp_np_ref_plot$Estimate
# Calculate Odds Ratios and Confidence Intervals
filtered_results_df_cp_np_ref_plot <- filtered_results_df_cp_np_ref_plot %>%
  mutate(
    OR = exp(Estimate),
    Lower_CI = exp(Estimate - 1.96 * `Std. Error`),
    Upper_CI = exp(Estimate + 1.96 * `Std. Error`)
  )
filtered_results_df_cp_np_ref_plot$OR
# Reorder the variables for the plot
filtered_results_df_cp_np_ref_plot$Variable <- factor(filtered_results_df_cp_np_ref_plot$Variable,
                                                  levels = c("KRD_nCowsWghtDist.3000m.sum","KRD_nPoultryWghtDist.3000m.sum","KRD_nGoatsWghtDist.3000m.sum","KRD_nPigsWghtDist.3000m.sum","meca_RF_preds","tetw_RF_preds","staph_RF_preds","ecoli_RF_preds"))


filtered_results_df_cp_np_ref_plot <- filtered_results_df_cp_np_ref_plot %>%
  mutate(Variable = dplyr::recode(Variable,
                                  "ecoli_RF_preds" = "RF-modelled E. coli exposure",
                                  "staph_RF_preds" = "RF-modelled Staphylococcus spp. exposure",
                                  "tetw_RF_preds" = "RF-modelled tetW ARG exposure",
                                  "meca_RF_preds" = "RF-modelled mecA ARG exposure",
                                  "KRD_nPigsWghtDist.3000m.sum" = "Distance weighted number of pigs in 3000m",
                                  "KRD_nGoatsWghtDist.3000m.sum" = "Distance weighted number of goats in 3000m",
                                  "KRD_nPoultryWghtDist.3000m.sum" = "Distance weighted number of chickens in 3000m",
                                  "KRD_nCowsWghtDist.3000m.sum" = "Distance weighted number of cattle in 3000m"
  ))



filtered_results_df_cp_np_ref_plot <- filtered_results_df_cp_np_ref_plot %>%
  mutate(Significance = case_when(
    BH_adjusted_pvalue < 0.05 ~ "***",
    BH_adjusted_pvalue < 0.1 ~ "**",
    BH_adjusted_pvalue < 0.25 ~ "*",
    TRUE ~ ""
  ))
filtered_results_df_cp_np_ref_plot$OR

# Create heatmap data as before
heatmap_data_cp_np_ref <- filtered_results_df_cp_np_ref_plot %>%
  select(Variable, Cluster, OR, Significance) %>%
  dcast(Variable ~ Cluster, value.var = "OR")  # Reshape data for heatmap

# Convert to long format for ggplot
heatmap_long_cp_np_ref <- melt(heatmap_data_cp_np_ref, id.vars = "Variable", variable.name = "Cluster", value.name = "OR")

# Merge significance markers back into the long format dataframe
heatmap_long_cp_np_ref <- heatmap_long_cp_np_ref %>%
  left_join(filtered_results_df_cp_np_ref_plot %>% select(Variable, Cluster, Significance), by = c("Variable", "Cluster"))

# Step 3: Create the heatmap with significance markers
heatmap_residential_expo_cp_np_ref <- ggplot(heatmap_long_cp_np_ref, aes(x = Cluster, y = Variable, fill = OR)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = carto_pal(7, "Geyser")[1], 
    mid = carto_pal(7, "Geyser")[4], 
    high = carto_pal(7, "Geyser")[7], 
    midpoint = 1,
    name = "Odds Ratio"
  ) +
  labs(
    title = "Residential livestock exposure on NP clusters\n Control population - Dolo(1) as reference cluster",
    x = "Cluster",
    y = "Variables"
  ) +
  scale_y_discrete(labels = c(
    "RF-modelled E. coli exposure" = "RF-modelled *E. coli* exposure",
    "RF-modelled Staphylococcus spp. exposure" = "RF-modelled *Staphylococcus* spp. exposure",
    "RF-modelled tetW ARG exposure" = "RF-modelled *tetW* ARG exposure",
    "RF-modelled mecA ARG exposure" = "RF-modelled *mecA* ARG exposure",
    "Distance weighted number of pigs in 3000m" = "Distance weighted number of pigs in 3000m",
    "Distance weighted number of goats in 3000m" = "Distance weighted number of goats in 3000m",
    "Distance weighted number of chickens in 3000m" = "Distance weighted number of chickens in 3000m",
    "Distance weighted number of cattle in 3000m" = "Distance weighted number of cattle in 3000m"
  )) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5),
    axis.text.y = element_markdown()  # Enable markdown for y-axis labels
  ) +
  geom_text(aes(label = Significance), color = "black", size = 5, vjust = 0.5) 

heatmap_residential_expo_cp_np_ref
# Save the heatmap
ggsave("../Output/Cluster_analysis/CP_NP/Residential_livestock_expo_heatmap_ref.svg", heatmap_residential_expo_cp_np_ref, width = 6, height = 5)
```
## OP 
### Cluster count and visualisation 
```{r}
# First, we remove the GF samples from the phyloseq to include only the CPs
ps_RA_cp_op <- subset_samples(ps_RA_cpall_gf_op, population != "GF")
ps_RA_cp_op <- prune_taxa(taxa_sums(ps_RA_cp_op) > 0, ps_RA_cp_op)

# Check number in each cluster in the CP op samples
table(ps_RA_cp_op@sam_data$cluster)

# Create the plot with geom_bar for vertical stacking
# Count the number of samples in each cluster
cluster_counts_cp_op <- as.data.frame(table(ps_RA_cp_op@sam_data$cluster))
colnames(cluster_counts_cp_op) <- c("Cluster", "Count")
# Calculate the relative proportions of each cluster
cluster_counts_cp_op$Proportion <- cluster_counts_cp_op$Count / sum(cluster_counts_cp_op$Count)
write.csv(cluster_counts_cp_op, "../Output/Cluster_analysis/CP_OP/Cluster_counts_proportions_cp_op.csv")
# Bar plot of cluster numbers
bar_clusters_cp_op <- ggplot(data = cluster_counts_cp_op, aes(x = Cluster, y = (Proportion*100), fill = Cluster)) +
  geom_bar(stat = "identity") +  # Use stat = "identity" to directly use Proportion
  labs(title = "Bar Plot of Clusters in Control Population (OP)",
       x = "Clusters",            # X-axis now represents clusters
       y = "% of samples",          # Y-axis represents proportions
       fill = "Cluster") +
  scale_fill_manual(values = c(paletteer_d("pals::stepped")[c(13,20,10,16,3,23)])) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),      # Remove x-axis labels if needed
        axis.ticks.x = element_blank(),     # Remove x-axis ticks if needed
        legend.position = "right")

bar_clusters_cp_op
ggsave("../Output/Cluster_analysis/CP_OP/Bar_plot_cluster_proportions_clusters.svg", bar_clusters_cp_op, width = 8, height = 5)
```
### Logistic regression analysis
```{r}
# Convert sample data to a dataframe
sample_data_df_cp_op <- data.frame(ps_RA_cp_op@sam_data)

#### Logistic regression for continuous variables ####
# We conduct logistic regression to determine whether the probability of belonging to a specific cluster increases with higher values of each continuous variable.
# For RF-modelled concentrations, we use a multivariable logistic regression model per exposure agent i.e. cluster1 ~ e.coli + age + gender + season + smoking
# For distance-based variables, we test them all together in one multivariable logistic regression model i.e. cluster1 ~ goats+ cows + pigs + poultry + age + gender + season + smoking


# Since Logistic regression requires sufficient counts in each outcome category to generate reliable and stable parameter estimates, we will exclude some of the clusters with low counts - anything with below 10 counts (out of the 1000 CPs)
# Calculate cluster counts
cluster_counts_OP <- table(sample_data_df_cp_op$cluster)
# Identify clusters with counts >= 10
clusters_to_keep <- names(cluster_counts_OP[cluster_counts_OP >= 10])
# Filter the dataset to retain only rows with clusters in clusters_to_keep
sample_data_df_cp_np <- sample_data_df_cp_np %>%
  filter(cluster %in% clusters_to_keep)


# Define the columns where we want to replace NA values with 0
columns_to_replace_na <- c("KRD_nGoatsWghtDist.3000m.sum", 
                           "KRD_nCowsWghtDist.3000m.sum", 
                           "KRD_nPoultryWghtDist.3000m.sum", 
                           "KRD_nPigsWghtDist.3000m.sum")

# Replace NAs with 0 for the specified columns
for (column in columns_to_replace_na) {
  sample_data_df_cp_op[[column]] <- replace_na(sample_data_df_cp_op[[column]], 0)
}

# Initialize an empty data frame to store logistic regression results
logistic_results_df_cp_op <- data.frame()

# Define the additional variables for the multivariable model
additional_vars <- c("age", "gender", "smoked_ever", "sampling_season")

# Convert categorical data to factors and set reference levels
sample_data_df_cp_op$gender <- relevel(as.factor(sample_data_df_cp_op$gender), ref = "0") 
sample_data_df_cp_op$smoked_ever <- relevel(as.factor(sample_data_df_cp_op$smoked_ever), ref = "0")  
sample_data_df_cp_op$sampling_season <- relevel(as.factor(sample_data_df_cp_op$sampling_season), ref = "Summer")  

# Set continuous variables based on columns_to_replace_na
continuous_vars <- columns_to_replace_na

# Loop through each cluster
for (clust in unique(sample_data_df_cp_op$cluster)) {
  # Create a binary outcome for each cluster (1 if sample is in the cluster, 0 otherwise)
  sample_data_df_cp_op$in_cluster <- ifelse(sample_data_df_cp_op$cluster == clust, 1, 0)
  
  # Fit the multivariable logistic regression model for the continuous variables
  formula_multivariable <- as.formula(paste("in_cluster ~", paste(c(continuous_vars, additional_vars), collapse = " + ")))
  model_multivariable <- glm(formula_multivariable, 
                             data = sample_data_df_cp_op, 
                             family = binomial)
  
  # Extract summary statistics
  summary_stats <- as.data.frame(summary(model_multivariable)$coefficients)
  
  # Add cluster and variable names for clarity
  summary_stats$Cluster <- clust
  summary_stats$Variable <- rownames(summary_stats)
  
  # Append to the results data frame
  logistic_results_df_cp_op <- rbind(logistic_results_df_cp_op, summary_stats)
  
  # Run separate models for each RF predictor
  for (rf_var in c("ecoli_RF_preds", "staph_RF_preds", "tetw_RF_preds", "meca_RF_preds")) {
    rf_formula <- as.formula(paste("in_cluster ~", rf_var, "+ age + gender + smoked_ever + sampling_season"))
    
    model_rf <- glm(rf_formula, 
                    data = sample_data_df_cp_op, 
                    family = binomial)
    
    # Extract summary statistics
    rf_summary_stats <- as.data.frame(summary(model_rf)$coefficients)
    
    # Add cluster and variable names for clarity
    rf_summary_stats$Cluster <- clust
    rf_summary_stats$Variable <- rf_var
    
    # Append to the results data frame
    logistic_results_df_cp_op <- rbind(logistic_results_df_cp_op, rf_summary_stats)
  }
}


# Rearrange columns to show Cluster and Variable first (optional)
logistic_results_df_cp_op <- logistic_results_df_cp_op %>%
  select(Cluster, Variable, everything())

# Print the results
print(logistic_results_df_cp_op)

# Add a new column "Covariate" to logistic_results_df_cp_np by removing numbers from the end of each Variable name
logistic_results_df_cp_op$Covariate <- gsub("[0-9]+$", "", rownames(logistic_results_df_cp_op))


# Apply the BH adjustment globally across the entire set of p values from all models (not separately within each model)
logistic_results_df_cp_op$BH_adjusted_pvalue <- p.adjust(logistic_results_df_cp_op$`Pr(>|z|)`, method = "BH")

# Filter results and retain only rows of interest, then arrange columns for readability
# Define the covariates to filter by
covariates_to_keep <- c("ecoli_RF_preds", "staph_RF_preds", "tetw_RF_preds", "meca_RF_preds", 
                        "KRD_nGoatsWghtDist.3000m.sum", "KRD_nCowsWghtDist.3000m.sum", 
                        "KRD_nPoultryWghtDist.3000m.sum", "KRD_nPigsWghtDist.3000m.sum")

# Filter for rows where the Covariate column matches the specified covariates
filtered_results_df_cp_op <- logistic_results_df_cp_op %>%
  filter(Covariate %in% covariates_to_keep) %>%
  select(Cluster, Variable, everything(), BH_adjusted_pvalue)

# Print the filtered results
print(filtered_results_df_cp_op)

# Print and/or save the globally adjusted results
print(filtered_results_df_cp_op)
write.csv(filtered_results_df_cp_op, "../Output/Cluster_analysis/CP_OP/Logistic_regression_results_cp_op_all_adjusted.csv")

# This logistic regression analysis Without a reference category, means that we get estimates for the "odds ratio" for each cluster in relation to the rest of the clusters, rather than a direct comparison between a chosen "reference" cluster and all others.
# Without a reference group, the odds ratios in these models represent the likelihood of being in a given cluster vs. any other cluster combined, which can be harder to interpret in context





#### With Veill(6)/Strep(4)/Prev(11) clust ref category ####
# Select 'reference' cluster - by doing this the coefficients for the other clusters reflect how much more or less likely it is to belong to a specific cluster in comparison to the reference group. This makes the results easier to interpret.
# Logistic regression models with a reference category tend to be more stable, as the interpretation of the odds ratios is constrained in a meaningful way, rather than comparing each group against the entire dataset.

sample_data_df_cp_op_ref <- sample_data_df_cp_op
# Since Logistic regression requires sufficient counts in each outcome category to generate reliable and stable parameter estimates, we will exclude some of the clusters with low counts - anything with below 10 counts (out of the 1000 CPs)
# Calculate cluster counts
cluster_counts_OP <- table(sample_data_df_cp_op_ref$cluster)
# Identify clusters with counts >= 10
clusters_to_keep <- names(cluster_counts_OP[cluster_counts_OP >= 10])
# Filter the dataset to retain only rows with clusters in clusters_to_keep
sample_data_df_cp_op_ref <- sample_data_df_cp_op_ref %>%
  filter(cluster %in% clusters_to_keep)

# Define the columns where we want to replace NA values with 0
columns_to_replace_na <- c("KRD_nGoatsWghtDist.3000m.sum", 
                           "KRD_nCowsWghtDist.3000m.sum", 
                           "KRD_nPoultryWghtDist.3000m.sum", 
                           "KRD_nPigsWghtDist.3000m.sum")

# Replace NAs with 0 for the specified columns
for (column in columns_to_replace_na) {
  sample_data_df_cp_op_ref[[column]] <- replace_na(sample_data_df_cp_op_ref[[column]], 0)
}

# Initialize an empty data frame to store logistic regression results
logistic_results_df_cp_op_ref <- data.frame()
# Define the additional variables for the multivariable model
additional_vars <- c("age", "gender", "smoked_ever", "sampling_season")

# Convert categorical data to factors and set reference levels
# Set a reference category for the cluster variable - Dolo(1) clust is the most common and represents a healthy nasal microbiome- this cluster is composed of Dolosigranulum_pigrum_1: 43.93%; Corynebacterium_3: 16.05%; Corynebacterium_7: 15.45% 
# Convert categorical data to factors and set reference levels
sample_data_df_cp_op_ref$gender <- relevel(as.factor(sample_data_df_cp_op_ref$gender), ref = "0") 
sample_data_df_cp_op_ref$smoked_ever <- relevel(as.factor(sample_data_df_cp_op_ref$smoked_ever), ref = "0")  
sample_data_df_cp_op_ref$sampling_season <- relevel(as.factor(sample_data_df_cp_op_ref$sampling_season), ref = "Summer")

# Loop through each cluster (except the reference cluster)
for (clust in setdiff(unique(sample_data_df_cp_op_ref$cluster), "Veill(6)/Strep(4)/Prev(11) clust")) {
  # Create a binary outcome for each cluster (1 if sample is in the cluster, 0 otherwise)
  sample_data_df_cp_op_ref$in_cluster <- ifelse(sample_data_df_cp_op_ref$cluster == clust, 1, 0)
  
  # Fit the multivariable logistic regression model for the continuous variables
  formula_multivariable <- as.formula(paste("in_cluster ~", paste(c(continuous_vars, additional_vars), collapse = " + ")))
  model_multivariable <- glm(formula_multivariable, 
                             data = sample_data_df_cp_op_ref, 
                             family = binomial)
  
  # Extract summary statistics
  summary_stats <- as.data.frame(summary(model_multivariable)$coefficients)
  
  # Add cluster and variable names for clarity
  summary_stats$Cluster <- clust
  summary_stats$Variable <- rownames(summary_stats)
  
  # Append to the results data frame
  logistic_results_df_cp_op_ref <- rbind(logistic_results_df_cp_op_ref, summary_stats)

  # Run separate models for each RF predictor (ecoli, staph, etc.)
  for (rf_var in c("ecoli_RF_preds", "staph_RF_preds", "tetw_RF_preds", "meca_RF_preds")) {
    rf_formula <- as.formula(paste("in_cluster ~", rf_var, "+ age + gender + smoked_ever + sampling_season"))
    
    model_rf <- glm(rf_formula, 
                    data = sample_data_df_cp_op_ref, 
                    family = binomial)
    
    # Extract summary statistics
    rf_summary_stats <- as.data.frame(summary(model_rf)$coefficients)
    
    # Add cluster and variable names for clarity
    rf_summary_stats$Cluster <- clust
    rf_summary_stats$Variable <- rf_var
    
    # Append to the results data frame
    logistic_results_df_cp_op_ref <- rbind(logistic_results_df_cp_op_ref, rf_summary_stats)
  }
}

# Rearrange columns to show Cluster and Variable first (optional)
logistic_results_df_cp_op_ref <- logistic_results_df_cp_op_ref %>%
  select(Cluster, Variable, everything())

# Print and/or save the results
print(logistic_results_df_cp_op_ref)
write.csv(logistic_results_df_cp_op_ref, "../Output/Cluster_analysis/CP_OP/Logistic_regression_results_cp_op_all_ref.csv")


# Add a new column "Covariate" to logistic_results_df_cp_np by removing numbers from the end of each Variable name
logistic_results_df_cp_op_ref$Covariate <- gsub("[0-9]+$", "", rownames(logistic_results_df_cp_op_ref))

# Apply the BH adjustment globally across the entire set of p values from all models (not separately within each model)
logistic_results_df_cp_op_ref$BH_adjusted_pvalue <- p.adjust(logistic_results_df_cp_op_ref$`Pr(>|z|)`, method = "BH")

# Filter results and retain only rows of interest, then arrange columns for readability
# Define the covariates to filter by
covariates_to_keep <- c("ecoli_RF_preds", "staph_RF_preds", "tetw_RF_preds", "meca_RF_preds", 
                        "KRD_nGoatsWghtDist.3000m.sum", "KRD_nCowsWghtDist.3000m.sum", 
                        "KRD_nPoultryWghtDist.3000m.sum", "KRD_nPigsWghtDist.3000m.sum")

# Filter for rows where the Covariate column matches the specified covariates
filtered_results_df_cp_op_ref <- logistic_results_df_cp_op_ref %>%
  filter(Covariate %in% covariates_to_keep) %>%
  select(Cluster, Variable, everything(), BH_adjusted_pvalue)

# Print the filtered results
print(filtered_results_df_cp_op_ref)

# Print and/or save the globally adjusted results
print(filtered_results_df_cp_op_ref)
write.csv(filtered_results_df_cp_op_ref, "../Output/Cluster_analysis/CP_OP/Logistic_regression_results_cp_op_all_adjusted_with ref.csv")

```
### Heatmap of odds ratios
```{r}
#### No reference cluster ####
# Present the Odds ratio instead of the estimate - this tells us how the odds of belonging to a specific cluster change with each unit increase in the predictor variable. 
filtered_results_df_cp_op_plot <- filtered_results_df_cp_op %>%
  select(Cluster, Variable, Estimate, BH_adjusted_pvalue, `Std. Error`)

# Calculate Odds Ratios and Confidence Intervals
filtered_results_df_cp_op_plot <- filtered_results_df_cp_op_plot %>%
  mutate(
    OR = exp(Estimate),
    Lower_CI = exp(Estimate - 1.96 * `Std. Error`),
    Upper_CI = exp(Estimate + 1.96 * `Std. Error`)
  )

# Reorder the variables for the plot
filtered_results_df_cp_op_plot$Variable <- factor(filtered_results_df_cp_op_plot$Variable,
  levels = c("KRD_nCowsWghtDist.3000m.sum","KRD_nPoultryWghtDist.3000m.sum","KRD_nGoatsWghtDist.3000m.sum","KRD_nPigsWghtDist.3000m.sum","meca_RF_preds","tetw_RF_preds","staph_RF_preds","ecoli_RF_preds"))


filtered_results_df_cp_op_plot <- filtered_results_df_cp_op_plot %>%
  mutate(Variable = dplyr::recode(Variable,
    "ecoli_RF_preds" = "RF-modelled E. coli exposure",
    "staph_RF_preds" = "RF-modelled Staphylococcus spp. exposure",
    "tetw_RF_preds" = "RF-modelled tetW ARG exposure",
    "meca_RF_preds" = "RF-modelled mecA ARG exposure",
    "KRD_nPigsWghtDist.3000m.sum" = "Distance weighted number of pigs in 3000m",
    "KRD_nGoatsWghtDist.3000m.sum" = "Distance weighted number of goats in 3000m",
    "KRD_nPoultryWghtDist.3000m.sum" = "Distance weighted number of chickens in 3000m",
    "KRD_nCowsWghtDist.3000m.sum" = "Distance weighted number of cattle in 3000m"
  ))

heatmap_data_cp_op <- filtered_results_df_cp_op_plot %>%
  select(Variable, Cluster, OR) %>%
  dcast(Variable ~ Cluster, value.var = "OR")  # Reshape data for heatmap

filtered_results_df_cp_op_plot <- filtered_results_df_cp_op_plot %>%
  mutate(Significance = case_when(
    BH_adjusted_pvalue < 0.05 ~ "***",
    BH_adjusted_pvalue < 0.1 ~ "**",
    BH_adjusted_pvalue < 0.25 ~ "*",
    TRUE ~ ""
  ))

# Step 2: Create heatmap data as before
heatmap_data_cp_op <- filtered_results_df_cp_op_plot %>%
  select(Variable, Cluster, OR, Significance) %>%
  dcast(Variable ~ Cluster, value.var = "OR")  # Reshape data for heatmap

# Convert to long format for ggplot
heatmap_long_cp_op <- melt(heatmap_data_cp_op, id.vars = "Variable", variable.name = "Cluster", value.name = "OR")

# Merge significance markers back into the long format dataframe
heatmap_long_cp_op <- heatmap_long_cp_op %>%
  left_join(filtered_results_df_cp_op_plot %>% select(Variable, Cluster, Significance), by = c("Variable", "Cluster"))

# Step 3: Create the heatmap with significance markers
heatmap_residential_expo_cp_op <- ggplot(heatmap_long_cp_op, aes(x = Cluster, y = Variable, fill = OR)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = carto_pal(7, "Geyser")[1], 
    mid = carto_pal(7, "Geyser")[4], 
    high = carto_pal(7, "Geyser")[7], 
    midpoint = 1,
    name = "Odds Ratio"
  ) +
  labs(
    title = "Residential livestock exposure on OP clusters\n Control population - no reference cluster",
    x = "Cluster",
    y = "Variables"
  ) +
  scale_y_discrete(labels = c(
    "RF-modelled E. coli exposure" = "RF-modelled *E. coli* exposure",
    "RF-modelled Staphylococcus spp. exposure" = "RF-modelled *Staphylococcus* spp. exposure",
    "RF-modelled tetW ARG exposure" = "RF-modelled *tetW* ARG exposure",
    "RF-modelled mecA ARG exposure" = "RF-modelled *mecA* ARG exposure",
    "Distance weighted number of pigs in 3000m" = "Distance weighted number of pigs in 3000m",
    "Distance weighted number of goats in 3000m" = "Distance weighted number of goats in 3000m",
    "Distance weighted number of chickens in 3000m" = "Distance weighted number of chickens in 3000m",
    "Distance weighted number of cattle in 3000m" = "Distance weighted number of cattle in 3000m"
  )) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5),
    axis.text.y = element_markdown()  # Enable markdown for y-axis labels
  ) +
  geom_text(aes(label = Significance), color = "black", size = 5, vjust = 0.5)  # Add significance labels

# Save the heatmap
ggsave("../Output/Cluster_analysis/CP_OP/Residential_livestock_expo_heatmap.svg", heatmap_residential_expo_cp_op, width = 6, height = 5)



#### With  ref category ####
# Present the Odds ratio instead of the estimate - this tells us how the odds of belonging to a specific cluster change with each unit increase in the predictor variable. 
filtered_results_df_cp_op_plot_ref <- filtered_results_df_cp_op_ref %>%
  select(Cluster, Variable, Estimate, BH_adjusted_pvalue, `Std. Error`)

# Calculate Odds Ratios and Confidence Intervals
filtered_results_df_cp_op_plot_ref <- filtered_results_df_cp_op_plot_ref %>%
  mutate(
    OR = exp(Estimate),
    Lower_CI = exp(Estimate - 1.96 * `Std. Error`),
    Upper_CI = exp(Estimate + 1.96 * `Std. Error`)
  )

# Reorder the variables for the plot
filtered_results_df_cp_op_plot_ref$Variable <- factor(filtered_results_df_cp_op_plot_ref$Variable,
                                                  levels = c("KRD_nCowsWghtDist.3000m.sum","KRD_nPoultryWghtDist.3000m.sum","KRD_nGoatsWghtDist.3000m.sum","KRD_nPigsWghtDist.3000m.sum","meca_RF_preds","tetw_RF_preds","staph_RF_preds","ecoli_RF_preds"))


filtered_results_df_cp_op_plot_ref <- filtered_results_df_cp_op_plot_ref %>%
  mutate(Variable = dplyr::recode(Variable,
                                  "ecoli_RF_preds" = "RF-modelled E. coli exposure",
                                  "staph_RF_preds" = "RF-modelled Staphylococcus spp. exposure",
                                  "tetw_RF_preds" = "RF-modelled tetW ARG exposure",
                                  "meca_RF_preds" = "RF-modelled mecA ARG exposure",
                                  "KRD_nPigsWghtDist.3000m.sum" = "Distance weighted number of pigs in 3000m",
                                  "KRD_nGoatsWghtDist.3000m.sum" = "Distance weighted number of goats in 3000m",
                                  "KRD_nPoultryWghtDist.3000m.sum" = "Distance weighted number of chickens in 3000m",
                                  "KRD_nCowsWghtDist.3000m.sum" = "Distance weighted number of cattle in 3000m"
  ))

heatmap_data_cp_op_ref <- filtered_results_df_cp_op_plot_ref %>%
  select(Variable, Cluster, OR) %>%
  dcast(Variable ~ Cluster, value.var = "OR")  # Reshape data for heatmap

filtered_results_df_cp_op_plot_ref <- filtered_results_df_cp_op_plot_ref %>%
  mutate(Significance = case_when(
    BH_adjusted_pvalue < 0.05 ~ "***",
    BH_adjusted_pvalue < 0.1 ~ "**",
    BH_adjusted_pvalue < 0.25 ~ "*",
    TRUE ~ ""
  ))

# Step 2: Create heatmap data as before
heatmap_data_cp_op_ref <- filtered_results_df_cp_op_plot_ref %>%
  select(Variable, Cluster, OR, Significance) %>%
  dcast(Variable ~ Cluster, value.var = "OR")  # Reshape data for heatmap

# Convert to long format for ggplot
heatmap_long_cp_op_ref <- melt(heatmap_data_cp_op_ref, id.vars = "Variable", variable.name = "Cluster", value.name = "OR")

# Merge significance markers back into the long format dataframe
heatmap_long_cp_op_ref <- heatmap_long_cp_op_ref %>%
  left_join(filtered_results_df_cp_op_plot_ref %>% select(Variable, Cluster, Significance), by = c("Variable", "Cluster"))

# Step 3: Create the heatmap with significance markers
heatmap_residential_expo_cp_op_ref <- ggplot(heatmap_long_cp_op_ref, aes(x = Cluster, y = Variable, fill = OR)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = carto_pal(7, "Geyser")[1], 
    mid = carto_pal(7, "Geyser")[4], 
    high = carto_pal(7, "Geyser")[7], 
    midpoint = 1,
    name = "Odds Ratio"
  ) +
  labs(
    title = "Residential livestock exposure on OP clusters\n Control population - Veill(6)/Strep(4)/Prev(11) as reference cluster",
    x = "Cluster",
    y = "Variables"
  ) +
  scale_y_discrete(labels = c(
    "RF-modelled E. coli exposure" = "RF-modelled *E. coli* exposure",
    "RF-modelled Staphylococcus spp. exposure" = "RF-modelled *Staphylococcus* spp. exposure",
    "RF-modelled tetW ARG exposure" = "RF-modelled *tetW* ARG exposure",
    "RF-modelled mecA ARG exposure" = "RF-modelled *mecA* ARG exposure",
    "Distance weighted number of pigs in 3000m" = "Distance weighted number of pigs in 3000m",
    "Distance weighted number of goats in 3000m" = "Distance weighted number of goats in 3000m",
    "Distance weighted number of chickens in 3000m" = "Distance weighted number of chickens in 3000m",
    "Distance weighted number of cattle in 3000m" = "Distance weighted number of cattle in 3000m"
  )) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5),
    axis.text.y = element_markdown()  # Enable markdown for y-axis labels
  ) +
  geom_text(aes(label = Significance), color = "black", size = 5, vjust = 0.5)  # Add significance labels

# Save the heatmap
ggsave("../Output/Cluster_analysis/CP_OP/Residential_livestock_expo_heatmap_ref.svg", heatmap_residential_expo_cp_op_ref, width = 6, height = 5)

```


# Goat farmers & controls (subset)
## NP
### Cluster count and visualisation 
```{r}
# Phyloseq with the GFs and matched controls
ps_cp_gf_matched <- readRDS("../Output/Phyloseq/ps_complete_matchedCPGF.rds")
# Extract sample names from the ps_cp_gf_matched object to get samples we need
sample_names_to_keep_cp_gf_np <- sample_names(ps_cp_gf_matched)
# Prune the ps_RA_cpall_gf_np object to keep only these samples
ps_RA_cp_gf_subset <- prune_samples(sample_names_to_keep_cp_gf_np, ps_RA_cpall_gf_np)
ps_RA_cp_gf_subset <- prune_taxa(taxa_sums(ps_RA_cp_gf_subset) > 0, ps_RA_cp_gf_subset) # 1300 taxa left

# Filter for GF and CP populations
ps_RA_cp_gf <- subset_samples(ps_RA_cp_gf_subset, population == "GF")
ps_RA_cp_cp <- subset_samples(ps_RA_cp_gf_subset, population == "CP")

# Count samples in each cluster for GF population
table_GF <- table(ps_RA_cp_gf@sam_data$cluster)
cluster_counts_GF <- as.data.frame(table_GF)
colnames(cluster_counts_GF) <- c("Cluster", "Count")
cluster_counts_GF$Proportion <- cluster_counts_GF$Count / sum(cluster_counts_GF$Count)

# Save GF cluster counts to CSV
write.csv(cluster_counts_GF, "../Output/Cluster_analysis/CP_GF_NP/Cluster_counts_proportions_GF.csv")

# Count samples in each cluster for CP population
table_CP <- table(ps_RA_cp_cp@sam_data$cluster)
cluster_counts_CP <- as.data.frame(table_CP)
colnames(cluster_counts_CP) <- c("Cluster", "Count")
cluster_counts_CP$Proportion <- cluster_counts_CP$Count / sum(cluster_counts_CP$Count)

# Save CP cluster counts to CSV
write.csv(cluster_counts_CP, "../Output/Cluster_analysis/CP_GF_NP/Cluster_counts_proportions_CP.csv")

# Create bar plot for GF population
bar_clusters_GF <- ggplot(data = cluster_counts_GF, aes(x = Cluster, y = (Proportion * 100), fill = Cluster)) +
  geom_bar(stat = "identity") +
  labs(title = "Bar Plot of Clusters in NP of Goat Farmers",
       x = "Clusters",
       y = "% of samples",
       fill = "Cluster") +
  scale_fill_manual(values = c(paletteer_d("pals::stepped")[c(13,20,10,16,1,18,21,5,12)])) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.position = "right")

# Save GF bar plot
ggsave("../Output/Cluster_analysis/CP_GF_NP/Bar_plot_cluster_proportions_GF.svg", bar_clusters_GF, width = 8, height = 5)

# Create bar plot for CP population
bar_clusters_CP <- ggplot(data = cluster_counts_CP, aes(x = Cluster, y = (Proportion * 100), fill = Cluster)) +
  geom_bar(stat = "identity") +
  labs(title = "Bar Plot of Clusters in NP Control Population (subset)",
       x = "Clusters",
       y = "% of samples",
       fill = "Cluster") +
  scale_fill_manual(values = c(paletteer_d("pals::stepped")[c(13,20,10,16,1,18,21,5,12)])) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.position = "right")

# Save CP bar plot
ggsave("../Output/Cluster_analysis/CP_GF_NP/Bar_plot_cluster_proportions_CP.svg", bar_clusters_CP, width = 8, height = 5)

# Print tables for verification
print(cluster_counts_GF)
print(cluster_counts_CP)

```

### Logistic regression analysis
```{r}
# Extract sample data
sample_data_cp_gf_np <- ps_RA_cp_gf_subset@sam_data

# Create a summary table counting the number of individuals in each cluster by population
population_count_table_cp_gf_np <- sample_data_cp_gf_np %>%
  group_by(cluster, population) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  pivot_wider(names_from = population, values_from = Count, values_fill = 0) %>%
  # Calculate total counts for each population across all clusters
  mutate(Total_CP = sum(CP),
         Total_GF = sum(GF),
         Proportion_CP = CP / Total_CP * 100,  # Proportion of CP
         Proportion_GF = GF / Total_GF * 100)  # Proportion of GF

# Print the resulting table
print(population_count_table_cp_gf_np)

# Optionally, save the table to a CSV file
write.csv(population_count_table_cp_gf_np, "../Output/Cluster_analysis/CP_GF_NP/Population_cluster_count_table.csv", row.names = FALSE)


#### Logistic regression models per cluster
# Perform multivariable logistic regression for the different clusters to assess how population (adjusted for age, gender, smoking and season) influences the likelihood of belonging to each cluster. 
# Initialize an empty data frame to store logistic regression results

# Filter clusters with at least 5% prevalence in both groups
filtered_clusters_cp_gf_np <- population_count_table_cp_gf_np %>%
  filter(Proportion_CP >= 5 & Proportion_GF >= 5) %>%
  pull(cluster)

# Print the filtered clusters
print(filtered_clusters_cp_gf_np)

# Filter the main dataset for only the selected clusters
sample_data_cp_gf_np_filt <- data.frame(sample_data_cp_gf_np) %>%
  filter(cluster %in% filtered_clusters_cp_gf_np)

# Initialize an empty data frame to store logistic regression results
logistic_results_cp_gf_np <- data.frame()

# Define the additional variables for the multivariable model
additional_vars <- c("age", "gender", "smoked_ever", "sampling_season")

# Convert categorical data to factors and set reference levels
sample_data_cp_gf_np_filt$gender <- relevel(as.factor(sample_data_cp_gf_np_filt$gender), ref = "0") 
sample_data_cp_gf_np_filt$smoked_ever <- relevel(as.factor(sample_data_cp_gf_np_filt$smoked_ever), ref = "0")  
sample_data_cp_gf_np_filt$sampling_season <- relevel(as.factor(sample_data_cp_gf_np_filt$sampling_season), ref ="Summer")  

# Ensure the population variable exists and is a factor
if (!"population" %in% names(sample_data_cp_gf_np_filt)) {
  stop("Population variable not found in the dataset.")
}
sample_data_cp_gf_np_filt$population <- as.factor(sample_data_cp_gf_np_filt$population)

# Initialize vectors to collect p-values and estimates for the populationGF variable
populationGF_p_values <- c()
populationGF_estimates <- c()

# Initialize an empty data frame to store logistic regression results for each cluster
logistic_results_cp_gf_np <- data.frame()

# Loop through each cluster
for (clust in unique(sample_data_cp_gf_np_filt$cluster)) {
  # Create a binary outcome for each cluster (1 if sample is in the cluster, 0 otherwise)
  sample_data_cp_gf_np_filt$in_cluster <- ifelse(sample_data_cp_gf_np_filt$cluster == clust, 1, 0)
  
  # Debug: Check counts of 0s and 1s in `in_cluster`
  print(paste("Cluster:", clust))
  print(table(sample_data_cp_gf_np_filt$in_cluster))
  
  # Check if there is variation in `in_cluster`
  if (length(unique(sample_data_cp_gf_np_filt$in_cluster)) == 1) {
    print(paste("Skipping cluster", clust, "due to lack of variation in outcome"))
    next
  }
  
  # Fit the multivariable logistic regression model, including population and additional variables
  formula_multivariable <- as.formula(paste("in_cluster ~", paste(c("population", additional_vars), collapse = " + ")))
  
  model_multivariable <- tryCatch({
    glm(formula_multivariable, data = sample_data_cp_gf_np_filt, family = binomial)
  }, error = function(e) {
    print(paste("Error fitting model for cluster", clust, ":", e$message))
    return(NULL)
  })
  
  # Check if model fit was successful
  if (is.null(model_multivariable)) {
    logistic_results_cp_gf_np <- rbind(logistic_results_cp_gf_np, 
                                          data.frame(Cluster = clust, 
                                                     PopulationGF_Estimate = NA, 
                                                     PopulationGF_p_value = NA))
    next
  }
  
  # Extract coefficients if available
  model_coefficients <- summary(model_multivariable)$coefficients
  
  if ("populationGF" %in% rownames(model_coefficients)) {
    # Extract the p-value and estimate for the populationGF variable
    populationGF_p_value <- model_coefficients["populationGF", "Pr(>|z|)"]
    populationGF_estimate <- model_coefficients["populationGF", "Estimate"]
    
    # Append to the respective vectors
    populationGF_p_values <- c(populationGF_p_values, populationGF_p_value)
    populationGF_estimates <- c(populationGF_estimates, populationGF_estimate)
    
    # Save the cluster identifier along with p-value and estimate for reference
    logistic_results_cp_gf_np <- rbind(logistic_results_cp_gf_np, 
                                          data.frame(Cluster = clust, 
                                                     PopulationGF_Estimate = populationGF_estimate, 
                                                     PopulationGF_p_value = populationGF_p_value))
  } else {
    # If populationGF is not in the model, add NA for both estimate and p-value
    logistic_results_cp_gf_np <- rbind(logistic_results_cp_gf_np, 
                                          data.frame(Cluster = clust, 
                                                     PopulationGF_Estimate = NA, 
                                                     PopulationGF_p_value = NA))
  }
}

# Apply the Benjamini-Hochberg correction to the collected population GF p-values (excluding NA values)
logistic_results_cp_gf_np$Adjusted_p_value <- p.adjust(na.omit(populationGF_p_values), method = "BH")

# Print the final results showing each cluster, its estimate, original populationGF p-value, and the adjusted p-value
print(logistic_results_cp_gf_np)

# Optionally save the results
write.csv(logistic_results_cp_gf_np, "../Output/Cluster_analysis/CP_GF_NP/log_regression_populationGF_p_values_and_estimates.csv", row.names = FALSE)
```

### Heatmap of odds ratios
```{r}
# Present the Odds ratio instead of the estimate - this tells us how the odds of belonging to a specific cluster change with each unit increase in the predictor variable. 

# Select relevant columns from the original results DataFrame
logistic_results_df_cp_gf_np_filtered <- logistic_results_cp_gf_np %>%
  select(Cluster, PopulationGF_Estimate, Adjusted_p_value)

# Calculate Odds Ratios and add the 'Variable' column
logistic_results_df_cp_gf_np_filtered <- logistic_results_df_cp_gf_np_filtered %>%
  mutate(OR = exp(PopulationGF_Estimate),
         Variable = "Population")  # Ensure Variable column is created

logistic_results_df_cp_gf_np_filtered <- logistic_results_df_cp_gf_np_filtered %>%
  mutate(Significance = case_when(
    Adjusted_p_value < 0.05 ~ "***",
    Adjusted_p_value < 0.1 ~ "**",
    Adjusted_p_value < 0.25 ~ "*",
    TRUE ~ ""
  ))

# Reshape the data using the `dcast` function from the reshape2 package
heatmap_data_cp_gf_np <- logistic_results_df_cp_gf_np_filtered %>%
  select(Variable, Cluster, OR, Significance) %>%  # Include 'Variable' and 'OR' in selection
  dcast(Variable ~ Cluster, value.var = "OR")  # Use the OR for reshaping

# Convert to long format for ggplot heatmap
heatmap_data_cp_gf_np <- melt(heatmap_data_cp_gf_np, id.vars = "Variable", variable.name = "Cluster", value.name = "OR")

# Merge significance markers back into the long format dataframe
heatmap_data_cp_gf_np <- heatmap_data_cp_gf_np %>%
  left_join(logistic_results_df_cp_gf_np_filtered %>% select(Variable, Cluster, Significance), by = c("Variable", "Cluster"))

# Replace "Population" with "Goat farmer vs controls" in the Variable column
heatmap_data_cp_gf_np$Variable <- dplyr::recode(heatmap_data_cp_gf_np$Variable, "Population" = "Goat farmer vs controls")

# Re-plot the heatmap
heatmap_occupational_expo_np <- ggplot(heatmap_data_cp_gf_np, aes(x = Cluster, y = Variable, fill = OR)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = carto_pal(7, "Geyser")[1], 
    mid = carto_pal(7, "Geyser")[4], 
    high = carto_pal(7, "Geyser")[7], 
    midpoint = 1,
    name = "Odds Ratio"
  ) +
  labs(
    title = "Heatmap of Odds Ratios for\n Occupational Exposure on NP clusters",
    x = "Cluster", 
    y = NULL
  ) +  # Removed y-axis label here
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5),
    axis.text.y = element_markdown()  # Enable markdown for y-axis labels
  ) +
  geom_text(aes(label = Significance), color = "black", size = 5, vjust = 0.5)  # Add significance labels

heatmap_occupational_expo_np

ggsave("../Output/Cluster_analysis/CP_GF_NP/Occupational_livestock_expo_heatmap_NP.svg", heatmap_occupational_expo_np, width = 5, height= 3)



```

## OP
### Cluster count and visualisation 
```{r}
# Phyloseq with the GFs and matched controls
ps_cp_gf_matched <- readRDS("../Output/Phyloseq/ps_complete_matchedCPGF.rds")
# Extract sample names from the ps_cp_gf_matched object to get samples we need
sample_names_to_keep_cp_gf_op <- sample_names(ps_cp_gf_matched)
# Prune the ps_RA_cpall_gf_op object to keep only these samples
ps_RA_cp_gf_subset <- prune_samples(sample_names_to_keep_cp_gf_op, ps_RA_cpall_gf_op)
ps_RA_cp_gf_subset <- prune_taxa(taxa_sums(ps_RA_cp_gf_subset) > 0, ps_RA_cp_gf_subset) # 1300 taxa left

# Filter for GF and CP populations
ps_RA_cp_gf <- subset_samples(ps_RA_cp_gf_subset, population == "GF")
ps_RA_cp_cp <- subset_samples(ps_RA_cp_gf_subset, population == "CP")

# Count samples in each cluster for GF population
table_GF <- table(ps_RA_cp_gf@sam_data$cluster)
cluster_counts_GF <- as.data.frame(table_GF)
colnames(cluster_counts_GF) <- c("Cluster", "Count")
cluster_counts_GF$Proportion <- cluster_counts_GF$Count / sum(cluster_counts_GF$Count)

# Save GF cluster counts to CSV
write.csv(cluster_counts_GF, "../Output/Cluster_analysis/CP_GF_OP/Cluster_counts_proportions_GF.csv")

# Count samples in each cluster for CP population
table_CP <- table(ps_RA_cp_cp@sam_data$cluster)
cluster_counts_CP <- as.data.frame(table_CP)
colnames(cluster_counts_CP) <- c("Cluster", "Count")
cluster_counts_CP$Proportion <- cluster_counts_CP$Count / sum(cluster_counts_CP$Count)

# Save CP cluster counts to CSV
write.csv(cluster_counts_CP, "../Output/Cluster_analysis/CP_GF_OP/Cluster_counts_proportions_CP.csv")

# Create bar plot for GF population
bar_clusters_GF <- ggplot(data = cluster_counts_GF, aes(x = Cluster, y = (Proportion * 100), fill = Cluster)) +
  geom_bar(stat = "identity") +
  labs(title = "Bar Plot of Clusters in OP samples from goat farmers",
       x = "Clusters",
       y = "% of samples",
       fill = "Cluster") +
  scale_fill_manual(values = c(paletteer_d("pals::stepped")[c(13,20,10,16,3,23)])) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.position = "right")

# Save GF bar plot
ggsave("../Output/Cluster_analysis/CP_GF_op/Bar_plot_cluster_proportions_GF.svg", bar_clusters_GF, width = 8, height = 5)

# Create bar plot for CP population
bar_clusters_CP <- ggplot(data = cluster_counts_CP, aes(x = Cluster, y = (Proportion * 100), fill = Cluster)) +
  geom_bar(stat = "identity") +
  labs(title = "Bar Plot of Clusters in OP samples from goat farmers",
       x = "Clusters",
       y = "% of samples",
       fill = "Cluster") +
  scale_fill_manual(values = c(paletteer_d("pals::stepped")[c(13,20,10,16,3,23)])) +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.position = "right")

# Save CP bar plot
ggsave("../Output/Cluster_analysis/CP_GF_OP/Bar_plot_cluster_proportions_CP.svg", bar_clusters_CP, width = 8, height = 5)

# Print tables for verification
print(cluster_counts_GF)
print(cluster_counts_CP)

```

### Logistic regression analysis
```{r}
# Extract sample data
sample_data_cp_gf_op <- ps_RA_cp_gf_subset@sam_data

# Create a summary table counting the number of individuals in each cluster by population
population_count_table_cp_gf_op <- sample_data_cp_gf_op %>%
  group_by(cluster, population) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  pivot_wider(names_from = population, values_from = Count, values_fill = 0) %>%
  # Calculate total counts for each population across all clusters
  mutate(Total_CP = sum(CP),
         Total_GF = sum(GF),
         Proportion_CP = CP / Total_CP * 100,  # Proportion of CP
         Proportion_GF = GF / Total_GF * 100)  # Proportion of GF

# Print the resulting table
print(population_count_table_cp_gf_op)

# Optionally, save the table to a CSV file
write.csv(population_count_table_cp_gf_op, "../Output/Cluster_analysis/CP_GF_OP/Population_cluster_count_table.csv", row.names = FALSE)


#### Logistic regression models per cluster
# Perform multivariable logistic regression for the different clusters to assess how population (adjusted for age, gender, smoking and season) influences the likelihood of belonging to each cluster. 
# Initialize an empty data frame to store logistic regression results

# Filter clusters with at least 5% prevalence in both groups
filtered_clusters_cp_gf_op <- population_count_table_cp_gf_op %>%
  filter(Proportion_CP >= 5 & Proportion_GF >= 5) %>%
  pull(cluster)

# Print the filtered clusters
print(filtered_clusters_cp_gf_op)

# Filter the main dataset for only the selected clusters
sample_data_cp_gf_op_filt <- data.frame(sample_data_cp_gf_op) %>%
  filter(cluster %in% filtered_clusters_cp_gf_op)

# Initialize an empty data frame to store logistic regression results
logistic_results_cp_gf_op <- data.frame()

# Define the additional variables for the multivariable model
additional_vars <- c("age", "gender", "smoked_ever", "sampling_season")

# Convert categorical data to factors and set reference levels
sample_data_cp_gf_op_filt$gender <- relevel(as.factor(sample_data_cp_gf_op_filt$gender), ref = "0") 
sample_data_cp_gf_op_filt$smoked_ever <- relevel(as.factor(sample_data_cp_gf_op_filt$smoked_ever), ref = "0")  
sample_data_cp_gf_op_filt$sampling_season <- relevel(as.factor(sample_data_cp_gf_op_filt$sampling_season), ref ="Summer")  

# Ensure the population variable exists and is a factor
if (!"population" %in% names(sample_data_cp_gf_op_filt)) {
  stop("Population variable not found in the dataset.")
}
sample_data_cp_gf_op_filt$population <- as.factor(sample_data_cp_gf_op_filt$population)

# Initialize vectors to collect p-values and estimates for the populationGF variable
populationGF_p_values <- c()
populationGF_estimates <- c()

# Initialize an empty data frame to store logistic regression results for each cluster
logistic_results_cp_gf_op <- data.frame()

# Loop through each cluster
for (clust in unique(sample_data_cp_gf_op_filt$cluster)) {
  # Create a binary outcome for each cluster (1 if sample is in the cluster, 0 otherwise)
  sample_data_cp_gf_op_filt$in_cluster <- ifelse(sample_data_cp_gf_op_filt$cluster == clust, 1, 0)
  
  # Debug: Check counts of 0s and 1s in `in_cluster`
  print(paste("Cluster:", clust))
  print(table(sample_data_cp_gf_op_filt$in_cluster))
  
  # Check if there is variation in `in_cluster`
  if (length(unique(sample_data_cp_gf_op_filt$in_cluster)) == 1) {
    print(paste("Skipping cluster", clust, "due to lack of variation in outcome"))
    next
  }
  
  # Fit the multivariable logistic regression model, including population and additional variables
  formula_multivariable <- as.formula(paste("in_cluster ~", paste(c("population", additional_vars), collapse = " + ")))
  
  model_multivariable <- tryCatch({
    glm(formula_multivariable, data = sample_data_cp_gf_op_filt, family = binomial)
  }, error = function(e) {
    print(paste("Error fitting model for cluster", clust, ":", e$message))
    return(NULL)
  })
  
  # Check if model fit was successful
  if (is.null(model_multivariable)) {
    logistic_results_cp_gf_op <- rbind(logistic_results_cp_gf_op, 
                                          data.frame(Cluster = clust, 
                                                     PopulationGF_Estimate = NA, 
                                                     PopulationGF_p_value = NA))
    next
  }
  
  # Extract coefficients if available
  model_coefficients <- summary(model_multivariable)$coefficients
  
  if ("populationGF" %in% rownames(model_coefficients)) {
    # Extract the p-value and estimate for the populationGF variable
    populationGF_p_value <- model_coefficients["populationGF", "Pr(>|z|)"]
    populationGF_estimate <- model_coefficients["populationGF", "Estimate"]
    
    # Append to the respective vectors
    populationGF_p_values <- c(populationGF_p_values, populationGF_p_value)
    populationGF_estimates <- c(populationGF_estimates, populationGF_estimate)
    
    # Save the cluster identifier along with p-value and estimate for reference
    logistic_results_cp_gf_op <- rbind(logistic_results_cp_gf_op, 
                                          data.frame(Cluster = clust, 
                                                     PopulationGF_Estimate = populationGF_estimate, 
                                                     PopulationGF_p_value = populationGF_p_value))
  } else {
    # If populationGF is not in the model, add NA for both estimate and p-value
    logistic_results_cp_gf_op <- rbind(logistic_results_cp_gf_op, 
                                          data.frame(Cluster = clust, 
                                                     PopulationGF_Estimate = NA, 
                                                     PopulationGF_p_value = NA))
  }
}

# Apply the Benjamini-Hochberg correction to the collected populationGF p-values (excluding NA values)
logistic_results_cp_gf_op$Adjusted_p_value <- p.adjust(na.omit(populationGF_p_values), method = "BH")

# Print the final results showing each cluster, its estimate, original populationGF p-value, and the adjusted p-value
print(logistic_results_cp_gf_op)

# Optionally save the results
write.csv(logistic_results_cp_gf_op, "../Output/Cluster_analysis/CP_GF_OP/Logistic_regression_results_CPvsGF.csv", row.names = FALSE)
```

### Heatmap of odds ratios
```{r}
# Present the Odds ratio instead of the estimate - this tells us how the odds of belonging to a specific cluster change with each unit increase in the predictor variable. 

# Select relevant columns from the original results DataFrame
logistic_results_df_cp_gf_op_filtered <- logistic_results_cp_gf_op %>%
  select(Cluster, PopulationGF_Estimate, Adjusted_p_value)

# Calculate Odds Ratios and add the 'Variable' column
logistic_results_df_cp_gf_op_filtered <- logistic_results_df_cp_gf_op_filtered %>%
  mutate(OR = exp(PopulationGF_Estimate),
         Variable = "Population")  # Ensure Variable column is created

logistic_results_df_cp_gf_op_filtered <- logistic_results_df_cp_gf_op_filtered %>%
  mutate(Significance = case_when(
    Adjusted_p_value < 0.05 ~ "***",
    Adjusted_p_value < 0.1 ~ "**",
    Adjusted_p_value < 0.25 ~ "*",
    TRUE ~ ""
  ))

# Reshape the data using the `dcast` function from the reshape2 package
heatmap_data_cp_gf_op <- logistic_results_df_cp_gf_op_filtered %>%
  select(Variable, Cluster, OR, Significance) %>%  # Include 'Variable' and 'OR' in selection
  dcast(Variable ~ Cluster, value.var = "OR")  # Use the OR for reshaping

# Convert to long format for ggplot heatmap
heatmap_data_cp_gf_op <- melt(heatmap_data_cp_gf_op, id.vars = "Variable", variable.name = "Cluster", value.name = "OR")

# Merge significance markers back into the long format dataframe
heatmap_data_cp_gf_op <- heatmap_data_cp_gf_op %>%
  left_join(logistic_results_df_cp_gf_op_filtered %>% select(Variable, Cluster, Significance), by = c("Variable", "Cluster"))


# Replace "Population" with "Goat farmer vs controls" in the Variable column
heatmap_data_cp_gf_op$Variable <- dplyr::recode(heatmap_data_cp_gf_op$Variable, "Population" = "Goat farmer vs controls")

# Create the heatmap with italic formatting
heatmap_occupational_expo_op <- ggplot(heatmap_data_cp_gf_op, aes(x = Cluster, y = Variable, fill = OR)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = carto_pal(7, "Geyser")[1], 
    mid = carto_pal(7, "Geyser")[4], 
    high = carto_pal(7, "Geyser")[7], 
    midpoint = 1,
    name = "Odds Ratio"
  ) +
  labs(
    title = "Heatmap of Odds Ratios for\n Occupational Exposure on OP clusters",
    x = "Cluster",
    y = NULL
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5),
    axis.text.y = element_markdown()  # Enable markdown for y-axis labels
  )+
  geom_text(aes(label = Significance), color = "black", size = 5, vjust = 0.5)  # Add significance labels

heatmap_occupational_expo_op


# Save the heatmap
ggsave("../Output/Cluster_analysis/CP_GF_OP/Occupational_livestock_expo_heatmap_OP.svg", heatmap_occupational_expo_op, width = 5, height= 3)
```


# Combine heatmaps together
```{r}
# Adjust the legends for the heatmaps
hm1 <- heatmap_residential_expo_cp_np + theme(legend.position = 'right', 
                                              plot.title = element_blank(),
                                              axis.title.x = element_blank(),
                                              axis.title.y = element_blank())
hm2 <- heatmap_residential_expo_cp_op + theme(legend.position = 'none', 
                                              plot.title = element_blank(),
                                              axis.text.y = element_blank(), 
                                              axis.title.x = element_blank(),
                                              axis.title.y = element_blank())
hm3 <- heatmap_occupational_expo_np + theme(legend.position = 'none', 
                                              plot.title = element_blank(),
                                              axis.title.x = element_blank(),
                                              axis.title.y = element_blank())
hm4 <- heatmap_occupational_expo_op + theme(legend.position = 'none', 
                                              plot.title = element_blank(),
                                              axis.text.y = element_blank(), 
                                              axis.title.x = element_blank(),
                                              axis.title.y = element_blank())

# Create patchwork layout
layout_hm_final <- "
AAAAAAABBBBBBB
AAAAAAABBBBBBB
AAAAAAABBBBBBB
CCCCCCCDDDDDDD
"

# Combine the plots with the specified layout and guide options
final_plot <- hm1 + 
              hm2 + 
              hm3 + 
              hm4 + 
              plot_layout(design = layout_hm_final, guides = "collect")

# Save the plot with the adjusted legend
ggsave("../Output/Cluster_analysis/Logistic_regr_results_heatmap_combined.svg", plot = final_plot, height = 8, width = 8)

```
